{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d913f3-3c42-428e-9cc0-8d679d51897a",
   "metadata": {},
   "source": [
    "!pip install -r requirements.txt# PEFT 库 QLoRA 实战 - ChatGLM3-6B\n",
    "\n",
    "通常，模型被量化后不会进一步训练用于下游任务，因为由于权重和激活的较低精度，训练可能不稳定。\n",
    "\n",
    "但是由于PEFT方法只添加额外的可训练参数，这使得我们可以使用PEFT适配器（Adapter）来训练一个量化模型！将量化与PEFT结合起来可以成为在单个GPU上训练大模型的微调策略。\n",
    "\n",
    "例如，`QLoRA` 是一种将模型量化为4位然后使用LoRA进行训练的方法，使得在单个16GB GPU（本教程以 NVIDIA T4为例）上微调一个具有65B参数的大模型成为可能。\n",
    "\n",
    "THUDM Hugging Face 主页：https://huggingface.co/THUDM\n",
    "\n",
    "## 教程说明\n",
    "\n",
    "本教程使用 QLoRA 论文中介绍的量化技术：`NF4 数据类型`、`双量化` 和 `混合精度计算`，在 `ChatGLM3-6b` 模型上实现了 QLoRA 微调。并展示了完整的 QLoRA 微调流程，具体如下：\n",
    "\n",
    "- 数据准备\n",
    "    - 下载数据集\n",
    "    - 设计 Tokenizer 函数处理样本（map、shuffle、flatten）\n",
    "    - 自定义批量数据处理类 DataCollatorForChatGLM\n",
    "- 训练模型\n",
    "    - 加载 ChatGLM3-6B 量化模型\n",
    "    - PEFT 量化模型预处理（prepare_model_for_kbit_training）\n",
    "    - QLoRA 适配器配置（TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING）\n",
    "    - 微调训练超参数配置（TrainingArguments）\n",
    "    - 开启训练（trainer.train)\n",
    "    - 保存QLoRA模型（trainer.model.save_pretrained)\n",
    "- [模型推理](peft_chatglm_inference.ipynb)\n",
    "    - 加载 ChatGLM3-6B 基础模型\n",
    "    - 加载 ChatGLM3-6B QLoRA 模型（PEFT Adapter）\n",
    "    - 微调前后对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abf461c-2789-4515-b956-76c9acd6349f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:14:41.313928Z",
     "iopub.status.busy": "2025-02-28T13:14:41.313477Z",
     "iopub.status.idle": "2025-02-28T13:16:32.175170Z",
     "shell.execute_reply": "2025-02-28T13:16:32.174481Z",
     "shell.execute_reply.started": "2025-02-28T13:14:41.313897Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting torch==2.3.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/cb/e2/1bd899d3eb60c6495cf5d0d2885edacac08bde7a1407eadeb2ab36eca3c7/torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.37.2 (from -r requirements.txt (line 2))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/85/f6/c5065913119c41ecad148c34e3a861f719e16b89a522287213698da911fc/transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ffmpeg==1.4 (from -r requirements.txt (line 3))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from -r requirements.txt (line 4))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting timm==0.9.12 (from -r requirements.txt (line 5))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/01/a5/eeb717242343d9ca34e7de554a6c08d96a0cfc7005ece4f847b1753581a6/timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets==2.16.1 (from -r requirements.txt (line 6))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ec/93/454ada0d1b289a0f4a86ac88dbdeab54921becabac45da3da787d136628f/datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate==0.4.1 (from -r requirements.txt (line 7))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==1.3.2 (from -r requirements.txt (line 8))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d0/0b/26ad95cf0b747be967b15fb71a06f5ac67aba0fd2f9cd174de6edefc4674/scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.1.1 (from -r requirements.txt (line 9))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2f/0e/3b74e8f7c908082793adafb02753477f653ccd7e189f3ba070757d2d0e65/pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting peft==0.7.1 (from -r requirements.txt (line 10))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/8b/1b/aee2a330d050c493642d59ba6af51f3910cb138ea48ede228c84c204a5af/peft-0.7.1-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.26.1 (from -r requirements.txt (line 11))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a6/b9/44623bdb05595481107153182e7f4b9f2ef9d3b674938ad13842054dcbd8/accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autoawq==0.2.2 (from -r requirements.txt (line 12))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a9/f4/ded4058cf03086afa45135cea082cfd44bfd2e0e849e78166501a66159ac/autoawq-0.2.2-cp310-cp310-manylinux2014_x86_64.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optimum==1.17.0 (from -r requirements.txt (line 13))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9b/cb/c90e3f0cc0ca1bbcff3909ef88e6b4aecdec41aebc3539d691e6da1eefda/optimum-1.17.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting auto-gptq==0.6.0 (from -r requirements.txt (line 14))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/09/b2/c964b7f286ce5f782c1be0b46700091daa60a121b41e06d9a59047b45e57/auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes==0.41.3.post2 (from -r requirements.txt (line 15))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d9/8d/b62d4fb02587e293e5b91b68bbcaa2d88c6a0360b622e9521d4bd07a20cd/bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jiwer==3.0.3 (from -r requirements.txt (line 16))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/0d/4f/ee537ab20144811dd99321735ff92ef2b3a3230b77ed7454bed4c44d21fc/jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
      "Collecting soundfile==0.12.1 (from -r requirements.txt (line 17))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c1/07/7591f4efd29e65071c3a61b53725036ea8f73366a4920a481ebddaf8d0ca/soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting librosa==0.10.1 (from -r requirements.txt (line 18))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e2/a2/4f639c1168d7aada749a896afb4892a831e2041bebdcf636aebfe9e86556/librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio==4.13.0 (from -r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9e/4e/478214778c5902ad7e2122f3ad4cf9b7cf6ce2d49aace345d1d3db5da044/gradio-4.13.0-py3-none-any.whl (16.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trl==0.8.1 (from -r requirements.txt (line 20))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/89/12/bdad48d9eb5d2f3e71fdfaa3d634737a79375be7caa927c6e95aa05f9d4a/trl-0.8.1-py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai==1.30.1 (from -r requirements.txt (line 21))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/16/35/10bb93c51c446370cf760ea0e722c78755bbe0572aeb4663bf8c19c9b082/openai-1.30.1-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain==0.2.0 (from -r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6a/3a/66115e1986e21f7a4a855df2c769c35bea84ca26b31f4e08951a364bb983/langchain-0.2.0-py3-none-any.whl (973 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai==0.1.7 (from -r requirements.txt (line 23))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/10/27/43f785670a340363fe46e2893a80293fa12448584f19ba4f9e6d03673552/langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Collecting langchain-core==0.2.1 (from -r requirements.txt (line 24))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c1/d9/42bb3c89db1b21d3de5fdebfbdd695c5e0722273935c9ac4a2d84f4ec381/langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community==0.2.0 (from -r requirements.txt (line 25))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/1b/ad/59d9f88057c29d0a5d9ed786358bbbc8797bda347f3f007d51a651d2613a/langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (2024.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/4b/2a/0a131f572aa09f741c30ccd45a8e56316e8be8dfc7bc19bf0ab7cfef7b19/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.3.1 (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d7/69/8a9fde07d2d27a90e16488cdfe9878e985a247b2496a4b5b1a2126042528/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2->-r requirements.txt (line 2))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/1c/5d/cf5e122ce4f1a29f165b2a69dc33d1ff30bce303343d58a54775ddba5d51/tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/site-packages (from timm==0.9.12->-r requirements.txt (line 5)) (0.20.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/site-packages (from datasets==2.16.1->-r requirements.txt (line 6)) (19.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.16.1->-r requirements.txt (line 6))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1->-r requirements.txt (line 6))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets==2.16.1->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets==2.16.1->-r requirements.txt (line 6)) (0.70.16)\n",
      "Collecting fsspec (from torch==2.3.1->-r requirements.txt (line 1))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets==2.16.1->-r requirements.txt (line 6)) (3.11.12)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->-r requirements.txt (line 7))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 8)) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas==2.1.1->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas==2.1.1->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas==2.1.1->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from peft==0.7.1->-r requirements.txt (line 10)) (7.0.0)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.2->-r requirements.txt (line 12)) (0.23.0)\n",
      "Collecting autoawq-kernels (from autoawq==0.2.2->-r requirements.txt (line 12))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/98/a6/c48cf823c2d29731ae262a05e17d317165df7bef68a486e5840405b70cc0/autoawq_kernels-0.0.9-cp310-cp310-manylinux2014_x86_64.whl (37.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs (from optimum==1.17.0->-r requirements.txt (line 13))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (from auto-gptq==0.6.0->-r requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: rouge in /usr/local/lib/python3.10/site-packages (from auto-gptq==0.6.0->-r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: gekko in /usr/local/lib/python3.10/site-packages (from auto-gptq==0.6.0->-r requirements.txt (line 14)) (1.2.1)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/site-packages (from jiwer==3.0.3->-r requirements.txt (line 16)) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/site-packages (from jiwer==3.0.3->-r requirements.txt (line 16)) (3.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/site-packages (from soundfile==0.12.1->-r requirements.txt (line 17)) (1.17.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (0.61.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.10.1->-r requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (23.2.1)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==4.13.0->-r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/aa/f3/0b6ced594e51cc95d8c1fc1640d3623770d01e4969d29c0bd09945fafefa/altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (0.5.0)\n",
      "Collecting gradio-client==0.8.0 (from gradio==4.13.0->-r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c4/e7/5da3a4b6108f5e2e43d034d7923c3562f93beba8f3d13a0ec7c201a6f33c/gradio_client-0.8.0-py3-none-any.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (0.28.1)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==4.13.0->-r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (3.10.0)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (3.10.15)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio==4.13.0->-r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b5/5b/6651c288b08df3b8c1e2f8c1152201e0b25d240e22ddade0f1e242fc9fa0/pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m186.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (2.10.6)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (0.0.20)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (2.10.0)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.13.0->-r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/68/4f/12207897848a653d03ebbf6775a29d949408ded5f99b2d87198bc5c93508/tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio==4.13.0->-r requirements.txt (line 19)) (0.15.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/site-packages (from gradio==4.13.0->-r requirements.txt (line 19)) (0.34.0)\n",
      "Collecting tyro>=0.5.11 (from trl==0.8.1->-r requirements.txt (line 20))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/11/4f/5ba9e95cfe4b88ccb439b785356de7073b344abc30bf87ea767fedc0a257/tyro-0.9.16-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/site-packages (from openai==1.30.1->-r requirements.txt (line 21)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai==1.30.1->-r requirements.txt (line 21)) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from openai==1.30.1->-r requirements.txt (line 21)) (1.3.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a9/99/505feb8a9bc7027addaa2b312b8b306319cacbbd8a5231c4123ca1fa082a/SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m171.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/8f/f3/d01591229e9d0eec1e8106ed6f9b670f299beb1c94fed4aa335afa78acb0/langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/de/f0/63b06b99b730b9954f8709f6f7d9b8d076fa0a973e472efe278089bde42b/langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d2/3f/8ba87d9e287b9d385a02a7114ddcef61b26f86411e121c9003eb509a1773/tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/site-packages (from langchain-openai==0.1.7->-r requirements.txt (line 23)) (0.8.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.2.1->-r requirements.txt (line 24))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting packaging>=20.0 (from transformers==4.37.2->-r requirements.txt (line 2))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==0.8.0->gradio==4.13.0->-r requirements.txt (line 19))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/58/0a/7570e15661a0a546c3a1152d95fe8c05480459bab36247f0acbf41f01a41/websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 6)) (1.18.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==4.13.0->-r requirements.txt (line 19)) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==4.13.0->-r requirements.txt (line 19)) (1.26.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.30.1->-r requirements.txt (line 21)) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.30.1->-r requirements.txt (line 21)) (3.10)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0->soundfile==0.12.1->-r requirements.txt (line 17)) (2.22)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/34/75/51952c7b2d3873b44a0028b1bd26a25078c18f92f256608e8d1dc61b39fd/marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx->gradio==4.13.0->-r requirements.txt (line 19)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx->gradio==4.13.0->-r requirements.txt (line 19)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx->gradio==4.13.0->-r requirements.txt (line 19)) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.2.1->-r requirements.txt (line 24))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/06/76/9e0ca1b8881f64bf927f2205bf6c43a085c04646a71d911b3c05d76e90bb/langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a9/d9/31b1b5415be5201ec1ba34ab04f47a92c69174d7817d70b51693fb60e780/langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0->-r requirements.txt (line 22)) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==4.13.0->-r requirements.txt (line 19)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==4.13.0->-r requirements.txt (line 19)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==4.13.0->-r requirements.txt (line 19)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==4.13.0->-r requirements.txt (line 19)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==4.13.0->-r requirements.txt (line 19)) (3.2.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.10/site-packages (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 18)) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.10.1->-r requirements.txt (line 18)) (4.3.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.0->gradio==4.13.0->-r requirements.txt (line 19)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.0->gradio==4.13.0->-r requirements.txt (line 19)) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.1.1->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 2)) (2.3.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/cf/69/79e4d63b9387b48939096e25115b8af7cd8a90397a304f92436bcb21f5b2/greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.17.0->-r requirements.txt (line 13)) (5.29.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.13.0->-r requirements.txt (line 19)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.13.0->-r requirements.txt (line 19)) (13.9.4)\n",
      "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting docstring-parser>=0.15 (from tyro>=0.5.11->trl==0.8.1->-r requirements.txt (line 20))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d5/7c/e9fcff7623954d86bdc17782036cbf715ecab1bec4847c008557affe1ca8/docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.1->-r requirements.txt (line 20))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e2/d1/a1d3189e7873408b9dc396aef0d7926c198b0df2aa3ddb5b539d3e89a70f/shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro>=0.5.11->trl==0.8.1->-r requirements.txt (line 20))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/cf/4b/9a77dc721aa0b7f74440a42e4ef6f9a4fae7324e17f64f88b96f4c25cc05/typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of autoawq-kernels to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting autoawq-kernels (from autoawq==0.2.2->-r requirements.txt (line 12))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/02/55/95285ad43c658422161574ea8563212f49412438033e4d8f834d6d7948dd/autoawq_kernels-0.0.8-cp310-cp310-manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/90/40/14fd53e6a5b66a5d7672023bbb2c22c1cb17906fcb1c52ff6cdcda69f07e/autoawq_kernels-0.0.7-cp310-cp310-manylinux2014_x86_64.whl (33.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.17.0->-r requirements.txt (line 13))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.10/site-packages (from fastapi->gradio==4.13.0->-r requirements.txt (line 19)) (0.45.3)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.16.1->-r requirements.txt (line 6))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e7/a9/39cf856d03690af6fd570cf40331f1f79acdbb3132a9c35d2c5002f7f30b/multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/35/a8/36d8d7b3e46b377800d8dec47891cdf05842d1a2366909ae4a0c89fbc5e6/multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch==2.3.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from timm==0.9.12->-r requirements.txt (line 5))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/5e/44/32e2d2d174391374d5ff3c4691b802e8efda9ae27ab9062eca2255b006af/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/19/49/41359c7c1493beefa5cc3c3e4ff036ebc607635574bf6868ac9aae23c1ee/torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/72/55/e0b3821c5595a9a2c8ec98d234b4a0d1142d91daac61f007503d3158f857/torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/42/c2/24b4416c53445098221557e18de0de59539cbe56b580b13a4f079746f3eb/torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m152.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/08/04/17425bf3c0620465ee182cea5c674db4debab87ed0627145d38039cb2a9e/torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.13.0->-r requirements.txt (line 19)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.13.0->-r requirements.txt (line 19)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.13.0->-r requirements.txt (line 19)) (0.22.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.13.0->-r requirements.txt (line 19)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.13.0->-r requirements.txt (line 19)) (2.19.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0->-r requirements.txt (line 22))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.13.0->-r requirements.txt (line 19)) (0.1.2)\n",
      "Building wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=777688b1dfc2067c4a385315a9d0b75f9456955eb0393949b910c9ef4729c8f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/02/28/da9138be85fac58880bfab91ed9240feb8f8a61953824e9098\n",
      "Successfully built ffmpeg\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: ffmpeg, bitsandbytes, websockets, typeguard, triton, tomlkit, tenacity, shtab, pyarrow-hotfix, pillow, packaging, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jsonpointer, jiwer, importlib-resources, humanfriendly, greenlet, fsspec, ffmpeg-python, docstring-parser, dill, async-timeout, typing-inspect, SQLAlchemy, soundfile, scikit-learn, responses, pandas, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, marshmallow, jsonpatch, coloredlogs, tyro, torch, tokenizers, openai, librosa, langsmith, gradio-client, dataclasses-json, transformers, torchvision, langchain-core, autoawq-kernels, altair, accelerate, timm, peft, langchain-text-splitters, langchain-openai, gradio, datasets, trl, optimum, langchain, evaluate, autoawq, auto-gptq, langchain-community\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.45.2\n",
      "    Uninstalling bitsandbytes-0.45.2:\n",
      "      Successfully uninstalled bitsandbytes-0.45.2\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 14.2\n",
      "    Uninstalling websockets-14.2:\n",
      "      Successfully uninstalled websockets-14.2\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.13.2\n",
      "    Uninstalling tomlkit-0.13.2:\n",
      "      Successfully uninstalled tomlkit-0.13.2\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: soundfile\n",
      "    Found existing installation: soundfile 0.13.1\n",
      "    Uninstalling soundfile-0.13.1:\n",
      "      Successfully uninstalled soundfile-0.13.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.63.0\n",
      "    Uninstalling openai-1.63.0:\n",
      "      Successfully uninstalled openai-1.63.0\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.2.post1\n",
      "    Uninstalling librosa-0.10.2.post1:\n",
      "      Successfully uninstalled librosa-0.10.2.post1\n",
      "  Attempting uninstall: gradio-client\n",
      "    Found existing installation: gradio_client 1.7.0\n",
      "    Uninstalling gradio_client-1.7.0:\n",
      "      Successfully uninstalled gradio_client-1.7.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.3\n",
      "    Uninstalling transformers-4.48.3:\n",
      "      Successfully uninstalled transformers-4.48.3\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1\n",
      "    Uninstalling torchvision-0.20.1:\n",
      "      Successfully uninstalled torchvision-0.20.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.3.0\n",
      "    Uninstalling accelerate-1.3.0:\n",
      "      Successfully uninstalled accelerate-1.3.0\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 1.0.14\n",
      "    Uninstalling timm-1.0.14:\n",
      "      Successfully uninstalled timm-1.0.14\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "  Attempting uninstall: gradio\n",
      "    Found existing installation: gradio 5.16.0\n",
      "    Uninstalling gradio-5.16.0:\n",
      "      Successfully uninstalled gradio-5.16.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.2.0\n",
      "    Uninstalling datasets-3.2.0:\n",
      "      Successfully uninstalled datasets-3.2.0\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.15.0\n",
      "    Uninstalling trl-0.15.0:\n",
      "      Successfully uninstalled trl-0.15.0\n",
      "  Attempting uninstall: optimum\n",
      "    Found existing installation: optimum 1.24.0\n",
      "    Uninstalling optimum-1.24.0:\n",
      "      Successfully uninstalled optimum-1.24.0\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.3\n",
      "    Uninstalling evaluate-0.4.3:\n",
      "      Successfully uninstalled evaluate-0.4.3\n",
      "  Attempting uninstall: autoawq\n",
      "    Found existing installation: autoawq 0.2.8\n",
      "    Uninstalling autoawq-0.2.8:\n",
      "      Successfully uninstalled autoawq-0.2.8\n",
      "  Attempting uninstall: auto-gptq\n",
      "    Found existing installation: auto_gptq 0.7.1\n",
      "    Uninstalling auto_gptq-0.7.1:\n",
      "      Successfully uninstalled auto_gptq-0.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xtuner 0.1.23 requires lagent>=0.1.2, which is not installed.\n",
      "xtuner 0.1.23 requires mmengine>=0.10.3, which is not installed.\n",
      "xtuner 0.1.23 requires scikit-image, which is not installed.\n",
      "evalscope 0.11.0 requires datasets<=3.2.0,>=3.0.0, but you have datasets 2.16.1 which is incompatible.\n",
      "hydra-core 1.3.2 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.7.2 which is incompatible.\n",
      "hydra-core 1.3.2 requires omegaconf<2.4,>=2.2, but you have omegaconf 2.0.6 which is incompatible.\n",
      "lmdeploy 0.7.0.post2 requires accelerate>=0.29.3, but you have accelerate 0.26.1 which is incompatible.\n",
      "lmdeploy 0.7.0.post2 requires outlines<0.1.0, but you have outlines 0.1.11 which is incompatible.\n",
      "lmdeploy 0.7.0.post2 requires triton<=3.1.0,>=3.0.0; sys_platform == \"linux\", but you have triton 2.3.1 which is incompatible.\n",
      "ms-opencompass 0.1.6 requires datasets>=2.18.0, but you have datasets 2.16.1 which is incompatible.\n",
      "ms-swift 3.2.0.dev0 requires datasets>=3.0, but you have datasets 2.16.1 which is incompatible.\n",
      "ms-swift 3.2.0.dev0 requires peft<0.15.0,>=0.11.0, but you have peft 0.7.1 which is incompatible.\n",
      "ms-swift 3.2.0.dev0 requires trl<0.16,>=0.13, but you have trl 0.8.1 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
      "torchaudio 2.5.1 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\n",
      "vllm 0.7.2 requires openai>=1.52.0, but you have openai 1.30.1 which is incompatible.\n",
      "vllm 0.7.2 requires tokenizers>=0.19.1, but you have tokenizers 0.15.2 which is incompatible.\n",
      "vllm 0.7.2 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\n",
      "vllm 0.7.2 requires torchvision==0.20.1, but you have torchvision 0.18.1 which is incompatible.\n",
      "vllm 0.7.2 requires transformers>=4.48.2, but you have transformers 4.37.2 which is incompatible.\n",
      "xformers 0.0.28.post3 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.38 accelerate-0.26.1 altair-5.5.0 async-timeout-4.0.3 auto-gptq-0.6.0 autoawq-0.2.2 autoawq-kernels-0.0.7 bitsandbytes-0.41.3.post2 coloredlogs-15.0.1 dataclasses-json-0.6.7 datasets-2.16.1 dill-0.3.7 docstring-parser-0.16 evaluate-0.4.1 ffmpeg-1.4 ffmpeg-python-0.2.0 fsspec-2023.10.0 gradio-4.13.0 gradio-client-0.8.0 greenlet-3.1.1 humanfriendly-10.0 importlib-resources-6.5.2 jiwer-3.0.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.0 langchain-community-0.2.0 langchain-core-0.2.1 langchain-openai-0.1.7 langchain-text-splitters-0.2.1 langsmith-0.1.147 librosa-0.10.1 marshmallow-3.26.1 multiprocess-0.70.15 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 openai-1.30.1 optimum-1.17.0 packaging-23.2 pandas-2.1.1 peft-0.7.1 pillow-10.4.0 pyarrow-hotfix-0.6 responses-0.18.0 scikit-learn-1.3.2 shtab-1.7.1 soundfile-0.12.1 tenacity-8.5.0 timm-0.9.12 tokenizers-0.15.2 tomlkit-0.12.0 torch-2.3.1 torchvision-0.18.1 transformers-4.37.2 triton-2.3.1 trl-0.8.1 typeguard-4.4.2 typing-inspect-0.9.0 tyro-0.9.16 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc2966d-9c0e-43f7-84d9-5b3c4712db23",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T13:16:49.314604Z",
     "iopub.status.busy": "2025-02-28T13:16:49.314249Z",
     "iopub.status.idle": "2025-02-28T13:16:49.318962Z",
     "shell.execute_reply": "2025-02-28T13:16:49.318266Z",
     "shell.execute_reply.started": "2025-02-28T13:16:49.314585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hf-mirror.com\n",
      "/mnt/workspace/huggingface/datasets/\n",
      "/mnt/workspace/huggingface/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "print(os.getenv('HF_ENDPOINT'))\n",
    "os.environ['HF_DATASETS_CACHE'] = '/mnt/workspace/huggingface/datasets/'\n",
    "print(os.getenv('HF_DATASETS_CACHE'))\n",
    "os.environ['HF_HOME'] = '/mnt/workspace/huggingface/'\n",
    "print(os.getenv('HF_HOME'))\n",
    "# os.environ['HF_HUB_OFFLINE']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa8105c-6dda-426b-9180-ab9abbc9ce9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:16:54.128052Z",
     "iopub.status.busy": "2025-02-28T13:16:54.127691Z",
     "iopub.status.idle": "2025-02-28T13:16:54.131723Z",
     "shell.execute_reply": "2025-02-28T13:16:54.131104Z",
     "shell.execute_reply.started": "2025-02-28T13:16:54.128031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义全局变量和参数\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'  # 模型ID或本地路径\n",
    "train_data_path = 'HasturOfficial/adgen'    # 训练数据路径\n",
    "eval_data_path = None                     # 验证数据路径，如果没有则设置为None\n",
    "seed = 8                                 # 随机种子\n",
    "max_input_length = 512                    # 输入的最大长度\n",
    "max_output_length = 1536                  # 输出的最大长度\n",
    "lora_rank = 4                             # LoRA秩\n",
    "lora_alpha = 32                           # LoRA alpha值\n",
    "lora_dropout = 0.05                       # LoRA Dropout率\n",
    "resume_from_checkpoint = None             # 如果从checkpoint恢复训练，指定路径\n",
    "prompt_text = ''                          # 所有数据前的指令文本\n",
    "compute_dtype = 'fp32'                    # 计算数据类型（fp32, fp16, bf16）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eab798-4ec0-45f0-af87-a3aa880f0888",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "### 下载数据集\n",
    "\n",
    "从 Hugging Face 加载 adgen 数据集，并tokenize，shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7517070-eae3-45e1-b6a2-f49f332650ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:16:57.506491Z",
     "iopub.status.busy": "2025-02-28T13:16:57.506172Z",
     "iopub.status.idle": "2025-02-28T13:17:16.033236Z",
     "shell.execute_reply": "2025-02-28T13:17:16.032723Z",
     "shell.execute_reply.started": "2025-02-28T13:16:57.506473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 457/457 [00:00<00:00, 1.17MB/s]\n",
      "Downloading data: 100%|██████████| 27.6M/27.6M [00:04<00:00, 6.42MB/s]\n",
      "Downloading data: 100%|██████████| 260k/260k [00:01<00:00, 237kB/s]\n",
      "Generating train split: 100%|██████████| 114599/114599 [00:00<00:00, 296681.23 examples/s]\n",
      "Generating validation split: 100%|██████████| 1070/1070 [00:00<00:00, 49776.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd03e18-05b7-47c3-bb32-520fb6f0bef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:17:21.877980Z",
     "iopub.status.busy": "2025-02-28T13:17:21.877524Z",
     "iopub.status.idle": "2025-02-28T13:17:21.883870Z",
     "shell.execute_reply": "2025-02-28T13:17:21.883343Z",
     "shell.execute_reply.started": "2025-02-28T13:17:21.877959Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'summary'],\n",
       "        num_rows: 114599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['content', 'summary'],\n",
       "        num_rows: 1070\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea17c452-be25-4424-884d-14ba92c17b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:17:23.829926Z",
     "iopub.status.busy": "2025-02-28T13:17:23.829566Z",
     "iopub.status.idle": "2025-02-28T13:17:23.835493Z",
     "shell.execute_reply": "2025-02-28T13:17:23.835002Z",
     "shell.execute_reply.started": "2025-02-28T13:17:23.829901Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4ee2cc-e964-4a47-9b18-67f99d65ff73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:17:53.314848Z",
     "iopub.status.busy": "2025-02-28T13:17:53.314391Z",
     "iopub.status.idle": "2025-02-28T13:17:53.324886Z",
     "shell.execute_reply": "2025-02-28T13:17:53.324429Z",
     "shell.execute_reply.started": "2025-02-28T13:17:53.314811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>类型#裙*图案#碎花*图案#刺绣*裙型#a字*裙领型#翻领*裙款式#勾花镂空*裙款式#收腰</td>\n",
       "      <td>衣身通体融入了大面积的碎花，散发着小女人的味道，上身能够让你拥有高雅的气息和阳光般的美丽。钩花镂空的设计配合精美浪漫的立体绣花，那浮雕般凹凸质感如艺术品般精致，穿着非常唯美仙气。而简单的小翻领帅气利落，凸显干练的气质。a字裙摆不仅能够遮盖粗壮的部分，而且微收腰的剪裁可以突出身材的腰线，更显高挑修长。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>类型#裙*颜色#红色*风格#复古*风格#性感*图案#蝴蝶结*图案#复古*裙长#连衣裙*裙袖长#七分袖*裙领型#方领*裙袖型#喇叭袖*裙款式#绑带*裙款式#露肩</td>\n",
       "      <td>这款连衣裙的配色是一个亮点，红色&lt;UNK&gt;而纯，无论出街还是参加派对都灰十分吸睛。弹力肩的设计适合多种穿法，可做方领穿，优雅复古，也可做露肩穿，性感迷人。衣襟前的一排包扣用同色同布料包裹制作，小巧精致。七分袖做了喇叭袖和增加绑带的处理，绑上蝴蝶结后，可爱灵动。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>类型#裙*材质#网纱*图案#线条*裙长#半身裙*裙长#连衣裙*裙领型#圆领*裙袖型#蝙蝠袖*裙款式#拼接</td>\n",
       "      <td>这款时尚两件套连衣裙，甄选优质的面料，柔软亲肤又舒适。圆领的设计，有效的修饰柔美的颈部线条。时尚的蝙蝠袖，打造甜美的女性气质。此外拼接网纱半身裙，丰富视觉层次感，给人营造假两件的既视感，让你穿出自己的个性与时尚。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"], num_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ccc1b-3820-4f72-934d-3bb0875de954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b875200f-7e13-46d8-954d-bfaa76829769",
   "metadata": {},
   "source": [
    "### 使用 ChatGLM3-6b Tokenizer 处理数据\n",
    "\n",
    "\n",
    "关于 `ignore_label_id` 的设置：\n",
    "\n",
    "在许多自然语言处理和机器学习框架中，`ignore_label_id` 被设置为 -100 是一种常见的约定。这个特殊的值用于标记在计算损失函数时应该被忽略的目标标签。让我们详细了解一下这个选择的原因：\n",
    "\n",
    "1. **损失函数忽略特定值**：训练语言模型时，损失函数（例如交叉熵损失）通常只计算对于模型预测重要或关键的标签的损失。在某些情况下，你可能不希望某些标签对损失计算产生影响。例如，在序列到序列的模型中，输入部分的标签通常被设置为一个忽略值，因为只有输出部分的标签对于训练是重要的。\n",
    "\n",
    "2. **为何选择-100**：这个具体的值是基于实现细节选择的。在 PyTorch 的交叉熵损失函数中，可以指定一个 `ignore_index` 参数。当损失函数看到这个索引值时，它就会忽略对应的输出标签。使用 -100 作为默认值是因为它是一个不太可能出现在标签中的数字（特别是在处理分类问题时，标签通常是从0开始的正整数）。\n",
    "\n",
    "3. **标准化和通用性**：由于这种做法在多个库和框架中被采纳，-100 作为忽略标签的默认值已经变得相对标准化，这有助于维护代码的通用性和可读性。\n",
    "\n",
    "总的来说，将 `ignore_label_id` 设置为 -100 是一种在计算损失时排除特定标签影响的便捷方式。这在处理特定类型的自然语言处理任务时非常有用，尤其是在涉及序列生成或修改的任务中。\n",
    "\n",
    "#### 关于 ChatGLM3 的填充处理说明\n",
    "\n",
    "- input_id（query）里的填充补全了输入长度，目的是不改变原始文本的含义。\n",
    "- label（answer）里的填充会用来跟模型基于 query 生成的结果计算 Loss，为了不影响损失值计算，也需要设置。咱们计算损失时，是针对 answer 部分的 Embedding Vector，因此 label 这样填充，前面的序列就自动忽略掉了，只比较生成内容的 loss。因此，需要将answer前面的部分做忽略填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e3c1f1-1e5b-4452-babe-234c8ae15bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:18:32.233349Z",
     "iopub.status.busy": "2025-02-28T13:18:32.233014Z",
     "iopub.status.idle": "2025-02-28T13:18:40.628029Z",
     "shell.execute_reply": "2025-02-28T13:18:40.627457Z",
     "shell.execute_reply.started": "2025-02-28T13:18:32.233323Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# revision='b098244' 版本对应的 ChatGLM3-6B 设置 use_reentrant=False\n",
    "# 最新版本 use_reentrant 被设置为 True，会增加不必要的显存开销\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\n",
    "                                          trust_remote_code=True,\n",
    "                                          revision='b098244')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc4a0fd-3239-4cb4-bf3f-8d8fcfff9af0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:19:57.101495Z",
     "iopub.status.busy": "2025-02-28T13:19:57.101167Z",
     "iopub.status.idle": "2025-02-28T13:19:57.107367Z",
     "shell.execute_reply": "2025-02-28T13:19:57.106813Z",
     "shell.execute_reply.started": "2025-02-28T13:19:57.101476Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenize_func 函数\n",
    "def tokenize_func(example, tokenizer, ignore_label_id=-100):\n",
    "    \"\"\"\n",
    "    对单个数据样本进行tokenize处理。\n",
    "\n",
    "    参数:\n",
    "    example (dict): 包含'content'和'summary'键的字典，代表训练数据的一个样本。\n",
    "    tokenizer (transformers.PreTrainedTokenizer): 用于tokenize文本的tokenizer。\n",
    "    ignore_label_id (int, optional): 在label中用于填充的忽略ID，默认为-100。\n",
    "\n",
    "    返回:\n",
    "    dict: 包含'tokenized_input_ids'和'labels'的字典，用于模型训练。\n",
    "    \"\"\"\n",
    "\n",
    "    # 构建问题文本\n",
    "    question = prompt_text + example['content']\n",
    "    if example.get('input', None) and example['input'].strip():\n",
    "        question += f'\\n{example[\"input\"]}'\n",
    "\n",
    "    # 构建答案文本\n",
    "    answer = example['summary']\n",
    "\n",
    "    # 对问题和答案文本进行tokenize处理\n",
    "    q_ids = tokenizer.encode(text=question, add_special_tokens=False)\n",
    "    a_ids = tokenizer.encode(text=answer, add_special_tokens=False)\n",
    "\n",
    "    # 如果tokenize后的长度超过最大长度限制，则进行截断\n",
    "    if len(q_ids) > max_input_length - 2:  # 保留空间给gmask和bos标记\n",
    "        q_ids = q_ids[:max_input_length - 2]\n",
    "    if len(a_ids) > max_output_length - 1:  # 保留空间给eos标记\n",
    "        a_ids = a_ids[:max_output_length - 1]\n",
    "\n",
    "    # 构建模型的输入格式\n",
    "    input_ids = tokenizer.build_inputs_with_special_tokens(q_ids, a_ids)\n",
    "    question_length = len(q_ids) + 2  # 加上gmask和bos标记\n",
    "\n",
    "    # 构建标签，对于问题部分的输入使用ignore_label_id进行填充\n",
    "    labels = [ignore_label_id] * question_length + input_ids[question_length:]\n",
    "\n",
    "    return {'input_ids': input_ids, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576b3fa-156a-4486-a267-ad773172d90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cda56-a96a-4787-8db9-a712c82e2bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78a19ed-6862-42fa-896d-2c297b94ce41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:25:12.435467Z",
     "iopub.status.busy": "2025-02-28T13:25:12.435144Z",
     "iopub.status.idle": "2025-02-28T13:26:02.282873Z",
     "shell.execute_reply": "2025-02-28T13:26:02.282392Z",
     "shell.execute_reply.started": "2025-02-28T13:25:12.435447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 114599/114599 [00:49<00:00, 2299.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "column_names = dataset['train'].column_names\n",
    "tokenized_dataset = dataset['train'].map(\n",
    "    lambda example: tokenize_func(example, tokenizer),\n",
    "    batched=False, \n",
    "    remove_columns=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe0b50d-56cf-469f-9b35-0eb573cd1b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:26:03.895848Z",
     "iopub.status.busy": "2025-02-28T13:26:03.895406Z",
     "iopub.status.idle": "2025-02-28T13:26:03.905620Z",
     "shell.execute_reply": "2025-02-28T13:26:03.905072Z",
     "shell.execute_reply.started": "2025-02-28T13:26:03.895814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64790, 64792, 30910, 33467, 31010, 56778, 30998, 38317, 31010, 54766, 57507, 30998, 33692, 31010, 40962, 30998, 32799, 31010, 40589, 30998, 56778, 54625, 31010, 44724, 30998, 56778, 55500, 54811, 58709, 31010, 55097, 55759, 30998, 56778, 40877, 31010, 56069, 54762, 30998, 56778, 40877, 31010, 55097, 55759, 30998, 56778, 40877, 31010, 55144, 57046, 30910, 33730, 54766, 57507, 44724, 31123, 40589, 37880, 48260, 35245, 31123, 54766, 57507, 54542, 54766, 55106, 32048, 54581, 54651, 56069, 54762, 31123, 42141, 35212, 33253, 31123, 56719, 56822, 37880, 32696, 53259, 31155, 40962, 32698, 55115, 34172, 31735, 31123, 55554, 54535, 58553, 54944, 54891, 56839, 31123, 39232, 33888, 38395, 35752, 31155, ...]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 33730, 54766, 57507, 44724, 31123, 40589, 37880, 48260, 35245, 31123, 54766, 57507, 54542, 54766, 55106, 32048, 54581, 54651, 56069, 54762, 31123, 42141, 35212, 33253, 31123, 56719, 56822, 37880, 32696, 53259, 31155, 40962, 32698, 55115, 34172, 31735, 31123, 55554, 54535, 58553, 54944, 54891, 56839, 31123, 39232, 33888, 38395, 35752, 31155, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_dataset, num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b28ee0-2207-41c8-a4cf-166d6c2b7a42",
   "metadata": {},
   "source": [
    "### 数据集处理：shuffle & flatten \n",
    "\n",
    "洗牌(shuffle)会将数据集的索引列表打乱，以创建一个索引映射。\n",
    "\n",
    "然而，一旦您的数据集具有索引映射，速度可能会变慢10倍。这是因为需要额外的步骤来使用索引映射获取要读取的行索引，并且最重要的是，您不再连续地读取数据块。\n",
    "\n",
    "要恢复速度，需要再次使用 Dataset.flatten_indices()将整个数据集重新写入磁盘上，从而删除索引映射。\n",
    "\n",
    "ref: https://huggingface.co/docs/datasets/v2.15.0/en/package_reference/main_classes#datasets.Dataset.flatten_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75293898-f010-4cae-bf01-d58afc9dc214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:26:24.602903Z",
     "iopub.status.busy": "2025-02-28T13:26:24.602568Z",
     "iopub.status.idle": "2025-02-28T13:26:24.685086Z",
     "shell.execute_reply": "2025-02-28T13:26:24.684604Z",
     "shell.execute_reply.started": "2025-02-28T13:26:24.602885Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f17038-ec1a-4935-ae39-afca620c461d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:26:25.832580Z",
     "iopub.status.busy": "2025-02-28T13:26:25.832199Z",
     "iopub.status.idle": "2025-02-28T13:26:30.024997Z",
     "shell.execute_reply": "2025-02-28T13:26:30.024487Z",
     "shell.execute_reply.started": "2025-02-28T13:26:25.832556Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 114599/114599 [00:04<00:00, 27412.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc7921-95b1-45b5-a88e-2a80f9b25ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "281bac4d-4a57-4de3-991e-d62fbe15b6af",
   "metadata": {},
   "source": [
    "### 定义 DataCollatorForChatGLM 类 批量处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631a70f9-a75e-42d6-ad8b-5fd635db8d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:26:48.465405Z",
     "iopub.status.busy": "2025-02-28T13:26:48.465010Z",
     "iopub.status.idle": "2025-02-28T13:26:48.472373Z",
     "shell.execute_reply": "2025-02-28T13:26:48.471799Z",
     "shell.execute_reply.started": "2025-02-28T13:26:48.465376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# DataCollatorForChatGLM 类\n",
    "class DataCollatorForChatGLM:\n",
    "    \"\"\"\n",
    "    用于处理批量数据的DataCollator，尤其是在使用 ChatGLM 模型时。\n",
    "\n",
    "    该类负责将多个数据样本（tokenized input）合并为一个批量，并在必要时进行填充(padding)。\n",
    "\n",
    "    属性:\n",
    "    pad_token_id (int): 用于填充(padding)的token ID。\n",
    "    max_length (int): 单个批量数据的最大长度限制。\n",
    "    ignore_label_id (int): 在标签中用于填充的ID。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pad_token_id: int, max_length: int = 2048, ignore_label_id: int = -100):\n",
    "        \"\"\"\n",
    "        初始化DataCollator。\n",
    "\n",
    "        参数:\n",
    "        pad_token_id (int): 用于填充(padding)的token ID。\n",
    "        max_length (int): 单个批量数据的最大长度限制。\n",
    "        ignore_label_id (int): 在标签中用于填充的ID，默认为-100。\n",
    "        \"\"\"\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.ignore_label_id = ignore_label_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch_data: List[Dict[str, List]]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        处理批量数据。\n",
    "\n",
    "        参数:\n",
    "        batch_data (List[Dict[str, List]]): 包含多个样本的字典列表。\n",
    "\n",
    "        返回:\n",
    "        Dict[str, torch.Tensor]: 包含处理后的批量数据的字典。\n",
    "        \"\"\"\n",
    "        # 计算批量中每个样本的长度\n",
    "        len_list = [len(d['input_ids']) for d in batch_data]\n",
    "        batch_max_len = max(len_list)  # 找到最长的样本长度\n",
    "\n",
    "        input_ids, labels = [], []\n",
    "        for len_of_d, d in sorted(zip(len_list, batch_data), key=lambda x: -x[0]):\n",
    "            pad_len = batch_max_len - len_of_d  # 计算需要填充的长度\n",
    "            # 添加填充，并确保数据长度不超过最大长度限制\n",
    "            ids = d['input_ids'] + [self.pad_token_id] * pad_len\n",
    "            label = d['labels'] + [self.ignore_label_id] * pad_len\n",
    "            if batch_max_len > self.max_length:\n",
    "                ids = ids[:self.max_length]\n",
    "                label = label[:self.max_length]\n",
    "            input_ids.append(torch.LongTensor(ids))\n",
    "            labels.append(torch.LongTensor(label))\n",
    "\n",
    "        # 将处理后的数据堆叠成一个tensor\n",
    "        input_ids = torch.stack(input_ids)\n",
    "        labels = torch.stack(labels)\n",
    "\n",
    "        return {'input_ids': input_ids, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "790fb86b-7662-4c49-8e3b-3db239c60838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:27:19.239329Z",
     "iopub.status.busy": "2025-02-28T13:27:19.238984Z",
     "iopub.status.idle": "2025-02-28T13:27:19.242325Z",
     "shell.execute_reply": "2025-02-28T13:27:19.241553Z",
     "shell.execute_reply.started": "2025-02-28T13:27:19.239310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 准备数据整理器\n",
    "data_collator = DataCollatorForChatGLM(pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4124a3-e2a5-4e68-828b-3db3590d6f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f280438-3192-405d-a7bc-095831af197f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a223fcf-630a-4978-ad96-bfe93c6581ea",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "### 加载 ChatGLM3-6B 量化模型\n",
    "\n",
    "使用 `nf4` 量化数据类型加载模型，开启双量化配置，以`bf16`混合精度训练，预估显存占用接近4GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1480790-6035-4212-bc64-4292f6a908ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:27:50.720491Z",
     "iopub.status.busy": "2025-02-28T13:27:50.720132Z",
     "iopub.status.idle": "2025-02-28T13:27:50.734006Z",
     "shell.execute_reply": "2025-02-28T13:27:50.733528Z",
     "shell.execute_reply.started": "2025-02-28T13:27:50.720470Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, BitsAndBytesConfig\n",
    "\n",
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# QLoRA 量化配置\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8738b8-f510-4d9c-b789-d5afda67e39b",
   "metadata": {},
   "source": [
    "### 加载模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ab5f48-a7ce-492a-bb8b-4c0c3ff04bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:37:31.906025Z",
     "iopub.status.busy": "2025-02-28T13:37:31.905665Z",
     "iopub.status.idle": "2025-02-28T13:49:28.945405Z",
     "shell.execute_reply": "2025-02-28T13:49:28.944900Z",
     "shell.execute_reply.started": "2025-02-28T13:37:31.906004Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 7/7 [11:15<00:00, 96.46s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:35<00:00,  5.04s/it]\n",
      "/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# revision='b098244' 版本对应的 ChatGLM3-6B 设置 use_reentrant=False\n",
    "# 最新版本 use_reentrant 被设置为 True，会增加不必要的显存开销\n",
    "model = AutoModel.from_pretrained(model_name_or_path,\n",
    "                                  quantization_config=q_config,\n",
    "                                  device_map='auto',\n",
    "                                  trust_remote_code=True,\n",
    "                                  revision='b098244')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaabfe10-d762-498a-87f1-1506d2ea2fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:50:35.720637Z",
     "iopub.status.busy": "2025-02-28T13:50:35.720168Z",
     "iopub.status.idle": "2025-02-28T13:50:35.725791Z",
     "shell.execute_reply": "2025-02-28T13:50:35.725208Z",
     "shell.execute_reply.started": "2025-02-28T13:50:35.720615Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3739.69MiB\n"
     ]
    }
   ],
   "source": [
    "# 获取当前模型占用的 GPU显存（差值为预留给 PyTorch 的显存）\n",
    "memory_footprint_bytes = model.get_memory_footprint()\n",
    "memory_footprint_mib = memory_footprint_bytes / (1024 ** 2)  # 转换为 MiB\n",
    "\n",
    "print(f\"{memory_footprint_mib:.2f}MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58f580-34c9-4f7f-b4cb-86548f25f2b1",
   "metadata": {},
   "source": [
    "### 预处理量化模型\n",
    "\n",
    "预处理量化后的模型，使其可以支持低精度微调训练\n",
    "\n",
    "ref: https://huggingface.co/docs/peft/main/en/developer_guides/quantization#quantize-a-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f59a712-4829-4929-b795-31ffdfab1761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:50:47.301531Z",
     "iopub.status.busy": "2025-02-28T13:50:47.301188Z",
     "iopub.status.idle": "2025-02-28T13:50:47.356151Z",
     "shell.execute_reply": "2025-02-28T13:50:47.355717Z",
     "shell.execute_reply.started": "2025-02-28T13:50:47.301511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    }
   ],
   "source": [
    "from peft import TaskType, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "kbit_model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21649f5e-3f31-44ff-ab0b-82ef1614491a",
   "metadata": {},
   "source": [
    "### 自定义模型新增 Adapter \n",
    "\n",
    "当新的热门 transformer 网络架构（新模型）发布时，Huggingface 社区会尽力快速将它们添加到PEFT中。\n",
    "\n",
    "如果是 Hugging Face Transformers 库还未内置支持的模型，可以使用自定义模型的方式进行配置。\n",
    "\n",
    "具体来说，在初始化相应的微调配置类（例如`LoraConfig`）时，我们需要显式指定在哪些层新增适配器（Adapter），并将其设置正确。\n",
    "\n",
    "ref: https://huggingface.co/docs/peft/developer_guides/custom_models\n",
    "\n",
    "\n",
    "#### PEFT 适配模块设置\n",
    "\n",
    "\n",
    "在PEFT库的 [constants.py](https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py) 文件中定义了不同的 PEFT 方法，在各类大模型上的微调适配模块。\n",
    "\n",
    "通常，名称相同的模型架构也类似，应用微调方法时的适配器设置也几乎一致。\n",
    "\n",
    "例如，如果新模型架构是`mistral`模型的变体，并且您想应用 LoRA 微调。在 TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING中`mistral`包含[\"q_proj\", \"v_proj\"]。\n",
    "\n",
    "这表示说，对于`mistral`模型，LoRA 的 target_modules 通常是 [\"q_proj\", \"v_proj\"]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4dd1cb6-c1b4-430b-b031-c842ddc683a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:50:52.923414Z",
     "iopub.status.busy": "2025-02-28T13:50:52.923053Z",
     "iopub.status.idle": "2025-02-28T13:50:52.926375Z",
     "shell.execute_reply": "2025-02-28T13:50:52.925815Z",
     "shell.execute_reply.started": "2025-02-28T13:50:52.923395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\n",
    "\n",
    "target_modules = TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING['chatglm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "517018b1-dff0-4caf-a1ff-21933f95e4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:50:55.381830Z",
     "iopub.status.busy": "2025-02-28T13:50:55.381439Z",
     "iopub.status.idle": "2025-02-28T13:50:55.385672Z",
     "shell.execute_reply": "2025-02-28T13:50:55.385146Z",
     "shell.execute_reply.started": "2025-02-28T13:50:55.381806Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query_key_value']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b7c08-931e-4764-9bfb-4230bc825561",
   "metadata": {},
   "source": [
    "### LoRA 适配器配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab44290b-7bf2-44f0-ac36-ef0d41527224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:50:59.394754Z",
     "iopub.status.busy": "2025-02-28T13:50:59.394379Z",
     "iopub.status.idle": "2025-02-28T13:50:59.398332Z",
     "shell.execute_reply": "2025-02-28T13:50:59.397729Z",
     "shell.execute_reply.started": "2025-02-28T13:50:59.394734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    target_modules=target_modules,\n",
    "    r=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bee2f80a-ccac-4c85-965e-ce5e5be528e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:51:01.422842Z",
     "iopub.status.busy": "2025-02-28T13:51:01.422485Z",
     "iopub.status.idle": "2025-02-28T13:51:01.457442Z",
     "shell.execute_reply": "2025-02-28T13:51:01.456960Z",
     "shell.execute_reply.started": "2025-02-28T13:51:01.422821Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qlora_model = get_peft_model(kbit_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf0acae-9e20-4d30-9999-53c3079cc42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:51:03.471501Z",
     "iopub.status.busy": "2025-02-28T13:51:03.471168Z",
     "iopub.status.idle": "2025-02-28T13:51:03.476411Z",
     "shell.execute_reply": "2025-02-28T13:51:03.475825Z",
     "shell.execute_reply.started": "2025-02-28T13:51:03.471481Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 974,848 || all params: 6,244,558,848 || trainable%: 0.01561115883009451\n"
     ]
    }
   ],
   "source": [
    "qlora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84f15b-93e1-4d90-80b9-ead28cd98406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8043c51-fa42-4867-9382-103ad5b082f3",
   "metadata": {},
   "source": [
    "### 训练超参数配置\n",
    "\n",
    "- 1个epoch表示对训练集的所有样本进行一次完整的训练。\n",
    "- `num_train_epochs` 表示要完整进行多少个 epochs 的训练。\n",
    "\n",
    "#### 关于使用 num_train_epochs 时，训练总步数 `steps` 的计算方法\n",
    "\n",
    "- 训练总步数： `total_steps = steps/epoch * num_train_epochs` \n",
    "- 每个epoch的训练步数：`steps/epoch = num_train_examples / (batch_size * gradient_accumulation_steps)`\n",
    "\n",
    "\n",
    "**以 `adgen` 数据集为例计算**\n",
    "\n",
    "```json\n",
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['content', 'summary'],\n",
    "        num_rows: 114599\n",
    "    })\n",
    "    validation: Dataset({\n",
    "        features: ['content', 'summary'],\n",
    "        num_rows: 1070\n",
    "    })\n",
    "})\n",
    "```\n",
    "\n",
    "代入超参数和配置进行计算：\n",
    "\n",
    "```python\n",
    "num_train_epochs = 1\n",
    "num_train_examples = 114599\n",
    "batch_size = 16\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "\n",
    "steps = num_train_epochs * num_train_examples / (batch_size * gradient_accumulation_steps)\n",
    "      = 1 * 114599 / (16 * 4)\n",
    "      = 1790\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa527b7e-2dd6-46f0-ba7f-49f1430695a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"models/{model_name_or_path}\",          # 输出目录\n",
    "    per_device_train_batch_size=16,                     # 每个设备的训练批量大小\n",
    "    gradient_accumulation_steps=4,                     # 梯度累积步数\n",
    "    # per_device_eval_batch_size=8,                      # 每个设备的评估批量大小\n",
    "    learning_rate=1e-3,                                # 学习率\n",
    "    num_train_epochs=1,                                # 训练轮数\n",
    "    lr_scheduler_type=\"linear\",                        # 学习率调度器类型\n",
    "    warmup_ratio=0.1,                                  # 预热比例\n",
    "    logging_steps=10,                                 # 日志记录步数\n",
    "    save_strategy=\"steps\",                             # 模型保存策略\n",
    "    save_steps=100,                                    # 模型保存步数\n",
    "    # evaluation_strategy=\"steps\",                       # 评估策略\n",
    "    # eval_steps=500,                                    # 评估步数\n",
    "    optim=\"adamw_torch\",                               # 优化器类型\n",
    "    fp16=True,                                        # 是否使用混合精度训练\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563f6592-1dac-433e-8195-c24761350cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=qlora_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba1de6-6e37-42a1-9ff0-4e926dee5a74",
   "metadata": {},
   "source": [
    "#### 训练参数（用于演示）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a9d542-090d-4045-9a07-06d772a77665",
   "metadata": {},
   "source": [
    "steps = num_train_epochs * num_train_examples / (batch_size * gradient_accumulation_steps)\n",
    "      = 1 * 10000 / (16 * 4)\n",
    "      = 156.25 \n",
    "      \n",
    "最后取 steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6164c2c8-47b4-4472-a192-952d8e425554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:53:13.169310Z",
     "iopub.status.busy": "2025-02-28T13:53:13.169018Z",
     "iopub.status.idle": "2025-02-28T13:53:13.345525Z",
     "shell.execute_reply": "2025-02-28T13:53:13.345017Z",
     "shell.execute_reply.started": "2025-02-28T13:53:13.169289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_demo_args = TrainingArguments(\n",
    "    output_dir=f\"models/demo/{model_name_or_path}\",          # 输出目录\n",
    "    per_device_train_batch_size=16,                     # 每个设备的训练批量大小\n",
    "    gradient_accumulation_steps=4,                     # 梯度累积步数\n",
    "    learning_rate=1e-3,                                # 学习率\n",
    "    max_steps=200,                                     # 训练步数\n",
    "    lr_scheduler_type=\"linear\",                        # 学习率调度器类型\n",
    "    warmup_ratio=0.1,                                  # 预热比例\n",
    "    logging_steps=10,                                 # 日志记录步数\n",
    "    save_strategy=\"steps\",                             # 模型保存策略\n",
    "    save_steps=20,                                    # 模型保存步数\n",
    "    optim=\"adamw_torch\",                               # 优化器类型\n",
    "    fp16=True,                                        # 是否使用混合精度训练\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9655c7a7-75fd-4f0a-b190-e97a533c9bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:53:17.516814Z",
     "iopub.status.busy": "2025-02-28T13:53:17.516326Z",
     "iopub.status.idle": "2025-02-28T13:53:17.625047Z",
     "shell.execute_reply": "2025-02-28T13:53:17.624518Z",
     "shell.execute_reply.started": "2025-02-28T13:53:17.516792Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.91, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=qlora_model,\n",
    "        args=training_demo_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073aa2a-22f0-4ac1-ba93-5d8953ddb18f",
   "metadata": {},
   "source": [
    "### 开始训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07413af1-dff0-466a-adaa-00a80f327350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:53:24.278586Z",
     "iopub.status.busy": "2025-02-28T13:53:24.278116Z",
     "iopub.status.idle": "2025-02-28T14:29:07.052591Z",
     "shell.execute_reply": "2025-02-28T14:29:07.052032Z",
     "shell.execute_reply.started": "2025-02-28T13:53:24.278563Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 35:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.957800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.530600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.258900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=3.4485947418212892, metrics={'train_runtime': 2142.5467, 'train_samples_per_second': 5.974, 'train_steps_per_second': 0.093, 'total_flos': 7.69445766292439e+16, 'train_loss': 3.4485947418212892, 'epoch': 0.11})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "320cd8a8-3690-4a2b-b725-f4c1316646ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T14:38:49.258098Z",
     "iopub.status.busy": "2025-02-28T14:38:49.257564Z",
     "iopub.status.idle": "2025-02-28T14:38:49.620753Z",
     "shell.execute_reply": "2025-02-28T14:38:49.620199Z",
     "shell.execute_reply.started": "2025-02-28T14:38:49.258077Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(f\"models/demo/{model_name_or_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909f94a-b993-41b4-99f2-95a3b8b38c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111a492-d605-4b69-b98b-7db97e45f7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
