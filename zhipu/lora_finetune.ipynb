{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "id": "89b89f64d8f8053d"
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB及以上（推荐使用30系或A10等sm80架构以上的NVIDIA显卡进行尝试）\n",
    "内存：16GB\n",
    "RAM: 2.9 /16 GB\n",
    "GPU RAM: 15.5/16.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "id": "a7bd9a514ed09ea6"
   },
   "source": [
    "## 0. 环境检查\n",
    "首先，先检查代码的运行地址，确保运行地址处于 `finetune_demo` 中。\n",
    "并且，确保已经安装了 `requirements.txt`中的依赖。\n",
    "\n",
    "> 本 demo 中，不需要使用 deepspeed, mpi4py 两个依赖，如果您安装这两个依赖遇到问题，可以不安装这两个依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7703109d1443346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T05:29:22.200365Z",
     "start_time": "2024-04-14T05:29:22.080929Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-08T15:23:21.003954Z",
     "iopub.status.busy": "2025-03-08T15:23:21.003512Z",
     "iopub.status.idle": "2025-03-08T15:23:21.180880Z",
     "shell.execute_reply": "2025-03-08T15:23:21.180226Z",
     "shell.execute_reply.started": "2025-03-08T15:23:21.003923Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/ChatGLM3/finetune_demo\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a67262-6380-4504-a25b-41bb83c8550c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T01:27:32.281504Z",
     "iopub.status.busy": "2025-03-11T01:27:32.281161Z",
     "iopub.status.idle": "2025-03-11T01:27:58.840243Z",
     "shell.execute_reply": "2025-03-11T01:27:58.839709Z",
     "shell.execute_reply.started": "2025-03-11T01:27:32.281477Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: jieba>=0.42.1 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.42.1)\n",
      "Requirement already satisfied: ruamel_yaml>=0.18.6 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.18.10)\n",
      "Requirement already satisfied: rouge_chinese>=1.0.3 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: datasets>=2.18.0 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: peft>=0.10.0 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.14.0)\n",
      "Collecting deepspeed==0.16.2 (from -r requirements.txt (line 7))\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d6/79/49cdf7d168b9ddcefeec6fda7a094a98bb48b046d56c7f4b2e092124534f/deepspeed-0.16.2.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: mpi4py>=3.1.5 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.0.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (0.8.1)\n",
      "Requirement already satisfied: hjson in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (1.11.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (6.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (2.10.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (4.67.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/site-packages (from deepspeed==0.16.2->-r requirements.txt (line 7)) (12.560.30)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/site-packages (from ruamel_yaml>=0.18.6->-r requirements.txt (line 2)) (0.2.12)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from rouge_chinese>=1.0.3->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (7.3.2)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (4.3.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.18.0->-r requirements.txt (line 5)) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.25.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (4.48.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets>=2.18.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.2->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.2->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.18.0->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.18.0->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.18.0->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.18.0->-r requirements.txt (line 5)) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/site-packages (from torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.9)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.10/site-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.48)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/site-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (69.5.1)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.10.1)\n",
      "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets>=2.18.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets>=2.18.0->-r requirements.txt (line 5)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->datasets>=2.18.0->-r requirements.txt (line 5)) (2025.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers->peft>=0.10.0->-r requirements.txt (line 6)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/site-packages (from transformers->peft>=0.10.0->-r requirements.txt (line 6)) (0.21.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch->deepspeed==0.16.2->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (21.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.22.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.9.0.20241003)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.16.2-py3-none-any.whl size=1548035 sha256=1a16253f844b0ef7b6449fdf4daf832f59b9b95ab9dcf46585fc25fb0544f9bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/08/ee/703ef0d7bb23f63567f54501761c4f763b749a1f1e45cda9ca\n",
      "Successfully built deepspeed\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: deepspeed\n",
      "  Attempting uninstall: deepspeed\n",
      "    Found existing installation: deepspeed 0.16.3\n",
      "    Uninstalling deepspeed-0.16.3:\n",
      "      Successfully uninstalled deepspeed-0.16.3\n",
      "Successfully installed deepspeed-0.16.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af061bca-383f-4c99-801a-7c0edc9db898",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T01:27:58.841361Z",
     "iopub.status.busy": "2025-03-11T01:27:58.841080Z",
     "iopub.status.idle": "2025-03-11T01:28:09.324515Z",
     "shell.execute_reply": "2025-03-11T01:28:09.323892Z",
     "shell.execute_reply.started": "2025-03-11T01:27:58.841334Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting transformers==4.40.0\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/09/c8/844d5518a6aeb4ffdc0cf0cae65ae13dbe5838306728c5c640b5a6e2a0c9/transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/40/4f/eb78de4af3b17b589f43a369cbf0c3a7173f25c3d2cd93068852c07689aa/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.40.0) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2024.8.30)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.3\n",
      "    Uninstalling transformers-4.48.3:\n",
      "      Successfully uninstalled transformers-4.48.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xtuner 0.1.23 requires lagent>=0.1.2, which is not installed.\n",
      "xtuner 0.1.23 requires mmengine>=0.10.3, which is not installed.\n",
      "autoawq 0.2.8 requires huggingface-hub>=0.26.5, but you have huggingface-hub 0.25.2 which is incompatible.\n",
      "autoawq 0.2.8 requires transformers<=4.47.1,>=4.45.0, but you have transformers 4.40.0 which is incompatible.\n",
      "lmdeploy 0.6.2 requires peft<=0.11.1, but you have peft 0.14.0 which is incompatible.\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 1.0.14 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\n",
      "trl 0.15.0 requires transformers>=4.46.0, but you have transformers 4.40.0 which is incompatible.\n",
      "vllm 0.5.3 requires transformers>=4.42.4, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c305c8a6-f9ef-4f81-a4f4-e2aae23a281f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T23:42:14.383406Z",
     "iopub.status.busy": "2025-03-09T23:42:14.383027Z",
     "iopub.status.idle": "2025-03-09T23:42:19.023553Z",
     "shell.execute_reply": "2025-03-09T23:42:19.022941Z",
     "shell.execute_reply.started": "2025-03-09T23:42:14.383378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.40.0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /usr/local/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: adaseq, auto_gptq, autoawq, evalscope, lmdeploy, ms-opencompass, ms-swift, ms-vlmeval, optimum, pai-easycv, peft, sentence-transformers, text2sql-lgesql, transformers-stream-generator, trl, vllm, xtuner\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9079a90f-2a2a-44ea-a2b6-585be30da5fc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T01:28:09.325406Z",
     "iopub.status.busy": "2025-03-11T01:28:09.325163Z",
     "iopub.status.idle": "2025-03-11T01:29:33.250730Z",
     "shell.execute_reply": "2025-03-11T01:29:33.250163Z",
     "shell.execute_reply.started": "2025-03-11T01:28:09.325388Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting autoawq==0.2.1\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/38/39/6909607c10464147fdb472884cda6f85325139e7fd7fb8e558abb4951ae1/autoawq-0.2.1-cp310-cp310-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (4.40.0)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (4.12.2)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (2.3.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (1.3.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (3.2.0)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/site-packages (from autoawq==0.2.1) (0.23.0)\n",
      "Collecting autoawq-kernels (from autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/98/a6/c48cf823c2d29731ae262a05e17d317165df7bef68a486e5840405b70cc0/autoawq_kernels-0.0.9-cp310-cp310-manylinux2014_x86_64.whl (37.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/site-packages (from tokenizers>=0.12.1->autoawq==0.2.1) (0.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (3.16.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->autoawq==0.2.1) (12.6.77)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.1) (4.67.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate->autoawq==0.2.1) (6.1.0)\n",
      "Collecting torch>=2.0.1 (from autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/37/81/aa9ab58ec10264c1abe62c8b73f5086c3c558885d6beecebf699f0dbeaeb/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2c/14/91ae57cd4db3f9ef7aa99f4019cfa8d54cb4caa7e00975df6467e9725a9f/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ea/27/1795d86fe88ef397885f2e580ac37628ed058a92ed2c39dc8eac3adf0619/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m156.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==8.9.2.26->torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ae/71/1c91302526c45ab494c23f61c7a84aa568b8c1f9d196efa5993957faf906/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/db/f7/97a9ea26ed4bbbfc2d470994b8b4f338ef663be97b8f677519ac195e113d/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/78/a8/bcbb63b53a4b1234feeafb65544ee55495e1bb37ec31b999b963cbccfd1d/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/df/99/12cd266d6233f47d00daf3a72739872bdc10267d0383508b0b9c84a18bb6/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/87/20/199b8713428322a2f22b722c62b8cc278cc53dffa9705d744484b5035ee9/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton (from autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/01/65/3ffa90e158a2c82f0716eee8d26a725d241549b7d7aaf7e4f44ac03ebd89/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1 (from torch>=2.0.1->autoawq==0.2.1)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.1->autoawq==0.2.1) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/site-packages (from datasets->autoawq==0.2.1) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets->autoawq==0.2.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets->autoawq==0.2.1) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets->autoawq==0.2.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/site-packages (from datasets->autoawq==0.2.1) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets->autoawq==0.2.1) (3.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.1) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.1) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->autoawq==0.2.1) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets->autoawq==0.2.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets->autoawq==0.2.1) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->datasets->autoawq==0.2.1) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->autoawq==0.2.1) (1.16.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, autoawq-kernels, autoawq\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.3.1\n",
      "    Uninstalling triton-2.3.1:\n",
      "      Successfully uninstalled triton-2.3.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "  Attempting uninstall: autoawq\n",
      "    Found existing installation: autoawq 0.2.8\n",
      "    Uninstalling autoawq-0.2.8:\n",
      "      Successfully uninstalled autoawq-0.2.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xtuner 0.1.23 requires lagent>=0.1.2, which is not installed.\n",
      "xtuner 0.1.23 requires mmengine>=0.10.3, which is not installed.\n",
      "fairseq 0.12.2 requires hydra-core<1.1,>=1.0.7, but you have hydra-core 1.3.2 which is incompatible.\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
      "lmdeploy 0.6.2 requires peft<=0.11.1, but you have peft 0.14.0 which is incompatible.\n",
      "lmdeploy 0.6.2 requires torch<=2.4.0,>=2.0.0, but you have torch 2.6.0 which is incompatible.\n",
      "lmdeploy 0.6.2 requires triton<=3.0.0,>=2.2.0; sys_platform == \"linux\", but you have triton 3.2.0 which is incompatible.\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 1.0.14 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\n",
      "torchaudio 2.3.1 requires torch==2.3.1, but you have torch 2.6.0 which is incompatible.\n",
      "torchvision 0.18.1 requires torch==2.3.1, but you have torch 2.6.0 which is incompatible.\n",
      "trl 0.15.0 requires transformers>=4.46.0, but you have transformers 4.40.0 which is incompatible.\n",
      "vllm 0.5.3 requires torch==2.3.1, but you have torch 2.6.0 which is incompatible.\n",
      "vllm 0.5.3 requires transformers>=4.42.4, but you have transformers 4.40.0 which is incompatible.\n",
      "vllm-flash-attn 2.5.9.post1 requires torch==2.3.1, but you have torch 2.6.0 which is incompatible.\n",
      "xformers 0.0.27 requires torch==2.3.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed autoawq-0.2.1 autoawq-kernels-0.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install autoawq==0.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b66c160-40c1-413e-a1d7-f67ea9b6b2f2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T01:29:33.252013Z",
     "iopub.status.busy": "2025-03-11T01:29:33.251770Z",
     "iopub.status.idle": "2025-03-11T01:29:38.389340Z",
     "shell.execute_reply": "2025-03-11T01:29:38.388718Z",
     "shell.execute_reply.started": "2025-03-11T01:29:33.251995Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting peft==0.10.0\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b4/5d/758c00ba637bc850f35fff7fad442c470ac3d606fe586d881b0bed7ef5a5/peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (2.6.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (4.40.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (4.67.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (1.3.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/site-packages (from peft==0.10.0) (0.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.10.0) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2024.8.30)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xtuner 0.1.23 requires lagent>=0.1.2, which is not installed.\n",
      "xtuner 0.1.23 requires mmengine>=0.10.3, which is not installed.\n",
      "lmdeploy 0.6.2 requires torch<=2.4.0,>=2.0.0, but you have torch 2.6.0 which is incompatible.\n",
      "lmdeploy 0.6.2 requires triton<=3.0.0,>=2.2.0; sys_platform == \"linux\", but you have triton 3.2.0 which is incompatible.\n",
      "ms-swift 3.2.0.dev0 requires peft<0.15.0,>=0.11.0, but you have peft 0.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed peft-0.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50e92810011977",
   "metadata": {},
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T05:29:23.809255Z",
     "start_time": "2024-04-14T05:29:22.202731Z"
    },
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-03-09T23:38:31.178272Z",
     "iopub.status.busy": "2025-03-09T23:38:31.177932Z",
     "iopub.status.idle": "2025-03-09T23:38:32.809963Z",
     "shell.execute_reply": "2025-03-09T23:38:32.809473Z",
     "shell.execute_reply.started": "2025-03-09T23:38:31.178245Z"
    },
    "id": "initial_id",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "id": "a1b7a99923349056"
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T06:23:41.282431Z",
     "start_time": "2024-04-14T05:29:23.810692Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-10T02:12:47.968920Z",
     "iopub.status.busy": "2025-03-10T02:12:47.968592Z",
     "iopub.status.idle": "2025-03-10T03:55:15.179241Z",
     "shell.execute_reply": "2025-03-10T03:55:15.178639Z",
     "shell.execute_reply.started": "2025-03-10T02:12:47.968900Z"
    },
    "id": "17c87410a24d844f",
    "outputId": "e347fc7d-875e-40c9-c682-3e064100476b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:12:54.254285: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 10:12:54.295942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 10:12:55.662445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:20<00:00,  2.93s/it]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 1307.38 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "Detected kernel version 4.19.91, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "{'loss': 4.8301, 'grad_norm': 2.2433273792266846, 'learning_rate': 4.99e-05, 'epoch': 0.0}\n",
      "{'loss': 4.6027, 'grad_norm': 3.208772659301758, 'learning_rate': 4.9800000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 4.4922, 'grad_norm': 3.0436723232269287, 'learning_rate': 4.97e-05, 'epoch': 0.0}\n",
      "{'loss': 4.126, 'grad_norm': 3.473201036453247, 'learning_rate': 4.96e-05, 'epoch': 0.0}\n",
      "{'loss': 4.115, 'grad_norm': 2.7873141765594482, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8633, 'grad_norm': 3.000046968460083, 'learning_rate': 4.94e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8389, 'grad_norm': 2.9459006786346436, 'learning_rate': 4.93e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7424, 'grad_norm': 3.022383689880371, 'learning_rate': 4.92e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6338, 'grad_norm': 3.3131322860717773, 'learning_rate': 4.91e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7164, 'grad_norm': 3.500784397125244, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6703, 'grad_norm': 3.68021821975708, 'learning_rate': 4.89e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8447, 'grad_norm': 3.924165964126587, 'learning_rate': 4.88e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6146, 'grad_norm': 3.5524213314056396, 'learning_rate': 4.87e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7305, 'grad_norm': 4.472588539123535, 'learning_rate': 4.86e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6834, 'grad_norm': 3.7147164344787598, 'learning_rate': 4.85e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7426, 'grad_norm': 3.9987611770629883, 'learning_rate': 4.8400000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5738, 'grad_norm': 4.145022392272949, 'learning_rate': 4.83e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5725, 'grad_norm': 4.342411518096924, 'learning_rate': 4.82e-05, 'epoch': 0.01}\n",
      "{'loss': 3.549, 'grad_norm': 4.883769989013672, 'learning_rate': 4.8100000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5711, 'grad_norm': 4.542569160461426, 'learning_rate': 4.8e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5498, 'grad_norm': 5.0660271644592285, 'learning_rate': 4.79e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6426, 'grad_norm': 4.104506015777588, 'learning_rate': 4.78e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6084, 'grad_norm': 4.806451797485352, 'learning_rate': 4.77e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5078, 'grad_norm': 4.586629390716553, 'learning_rate': 4.76e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4754, 'grad_norm': 5.490573883056641, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6027, 'grad_norm': 5.411200046539307, 'learning_rate': 4.74e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5457, 'grad_norm': 5.486117362976074, 'learning_rate': 4.73e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6131, 'grad_norm': 4.601317882537842, 'learning_rate': 4.72e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6277, 'grad_norm': 4.856233596801758, 'learning_rate': 4.71e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5373, 'grad_norm': 5.945725917816162, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4648, 'grad_norm': 5.429440498352051, 'learning_rate': 4.69e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6031, 'grad_norm': 5.868764400482178, 'learning_rate': 4.6800000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4137, 'grad_norm': 5.3090033531188965, 'learning_rate': 4.6700000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 3.49, 'grad_norm': 5.406912803649902, 'learning_rate': 4.660000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5166, 'grad_norm': 5.629545211791992, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5721, 'grad_norm': 5.2979559898376465, 'learning_rate': 4.64e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3619, 'grad_norm': 4.985203742980957, 'learning_rate': 4.630000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5283, 'grad_norm': 5.183945178985596, 'learning_rate': 4.6200000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5184, 'grad_norm': 5.2555646896362305, 'learning_rate': 4.61e-05, 'epoch': 0.01}\n",
      "{'loss': 3.475, 'grad_norm': 5.61873197555542, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6912, 'grad_norm': 5.540368556976318, 'learning_rate': 4.5900000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4977, 'grad_norm': 5.085982799530029, 'learning_rate': 4.58e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6254, 'grad_norm': 5.641981601715088, 'learning_rate': 4.5700000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4162, 'grad_norm': 6.604604721069336, 'learning_rate': 4.5600000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4139, 'grad_norm': 6.249743938446045, 'learning_rate': 4.55e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4268, 'grad_norm': 5.646566390991211, 'learning_rate': 4.5400000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5307, 'grad_norm': 5.817060947418213, 'learning_rate': 4.53e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4459, 'grad_norm': 7.1878437995910645, 'learning_rate': 4.52e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4592, 'grad_norm': 5.853950500488281, 'learning_rate': 4.5100000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5645, 'grad_norm': 6.00339937210083, 'learning_rate': 4.5e-05, 'epoch': 0.02}\n",
      " 10%|███▊                                  | 500/5000 [07:29<1:17:06,  1.03s/it]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:25<00:25, 12.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:51<00:18, 18.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:09<00:00, 18.13s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.637 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 31.737781999999996, 'eval_rouge-2': 6.655630000000001, 'eval_rouge-l': 23.284587999999996, 'eval_bleu-4': 0.03006208394251145, 'eval_runtime': 96.4561, 'eval_samples_per_second': 0.518, 'eval_steps_per_second': 0.041, 'epoch': 0.02}\n",
      " 10%|███▊                                  | 500/5000 [09:05<1:17:06,  1.03s/it]\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:10<00:00, 18.13s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-500\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3195, 'grad_norm': 5.911309719085693, 'learning_rate': 4.49e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5459, 'grad_norm': 6.782844066619873, 'learning_rate': 4.4800000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5834, 'grad_norm': 6.073573112487793, 'learning_rate': 4.47e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4852, 'grad_norm': 5.409763336181641, 'learning_rate': 4.46e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5227, 'grad_norm': 5.419167995452881, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 3.6461, 'grad_norm': 5.900687217712402, 'learning_rate': 4.44e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4914, 'grad_norm': 5.840416431427002, 'learning_rate': 4.43e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3717, 'grad_norm': 5.582205295562744, 'learning_rate': 4.4200000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4232, 'grad_norm': 6.206880569458008, 'learning_rate': 4.41e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4893, 'grad_norm': 6.4783830642700195, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4391, 'grad_norm': 6.322536468505859, 'learning_rate': 4.39e-05, 'epoch': 0.02}\n",
      "{'loss': 3.457, 'grad_norm': 6.727654457092285, 'learning_rate': 4.38e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4477, 'grad_norm': 5.999641418457031, 'learning_rate': 4.3700000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4549, 'grad_norm': 6.331474781036377, 'learning_rate': 4.36e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5328, 'grad_norm': 5.9407525062561035, 'learning_rate': 4.35e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4799, 'grad_norm': 6.479826927185059, 'learning_rate': 4.3400000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5406, 'grad_norm': 6.178033351898193, 'learning_rate': 4.33e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3021, 'grad_norm': 7.156147003173828, 'learning_rate': 4.32e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3998, 'grad_norm': 6.6558661460876465, 'learning_rate': 4.3100000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3543, 'grad_norm': 6.309112548828125, 'learning_rate': 4.3e-05, 'epoch': 0.02}\n",
      "{'loss': 3.498, 'grad_norm': 7.011454105377197, 'learning_rate': 4.29e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5312, 'grad_norm': 6.803769111633301, 'learning_rate': 4.2800000000000004e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2443, 'grad_norm': 6.9559478759765625, 'learning_rate': 4.27e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5764, 'grad_norm': 5.8461480140686035, 'learning_rate': 4.26e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4006, 'grad_norm': 6.497403621673584, 'learning_rate': 4.25e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4771, 'grad_norm': 6.226401329040527, 'learning_rate': 4.24e-05, 'epoch': 0.03}\n",
      "{'loss': 3.6199, 'grad_norm': 6.5037760734558105, 'learning_rate': 4.23e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4736, 'grad_norm': 6.33563232421875, 'learning_rate': 4.22e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3289, 'grad_norm': 6.498635768890381, 'learning_rate': 4.21e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5502, 'grad_norm': 7.034459114074707, 'learning_rate': 4.2e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2896, 'grad_norm': 6.6857686042785645, 'learning_rate': 4.19e-05, 'epoch': 0.03}\n",
      "{'loss': 3.36, 'grad_norm': 6.600773334503174, 'learning_rate': 4.18e-05, 'epoch': 0.03}\n",
      "{'loss': 3.46, 'grad_norm': 7.330913543701172, 'learning_rate': 4.17e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4057, 'grad_norm': 6.471273422241211, 'learning_rate': 4.16e-05, 'epoch': 0.03}\n",
      "{'loss': 3.507, 'grad_norm': 6.241224765777588, 'learning_rate': 4.15e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5348, 'grad_norm': 6.336012840270996, 'learning_rate': 4.14e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2951, 'grad_norm': 7.202327728271484, 'learning_rate': 4.13e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4924, 'grad_norm': 6.718581199645996, 'learning_rate': 4.12e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4525, 'grad_norm': 7.478399276733398, 'learning_rate': 4.11e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2611, 'grad_norm': 7.937376022338867, 'learning_rate': 4.1e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4557, 'grad_norm': 7.862464904785156, 'learning_rate': 4.09e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4227, 'grad_norm': 6.9700236320495605, 'learning_rate': 4.08e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4598, 'grad_norm': 7.497722625732422, 'learning_rate': 4.07e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5678, 'grad_norm': 7.347685813903809, 'learning_rate': 4.0600000000000004e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3613, 'grad_norm': 6.46784782409668, 'learning_rate': 4.05e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4305, 'grad_norm': 7.902887344360352, 'learning_rate': 4.0400000000000006e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5314, 'grad_norm': 5.989173889160156, 'learning_rate': 4.0300000000000004e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3223, 'grad_norm': 7.01854133605957, 'learning_rate': 4.02e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4631, 'grad_norm': 7.405431747436523, 'learning_rate': 4.0100000000000006e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4, 'grad_norm': 7.961014747619629, 'learning_rate': 4e-05, 'epoch': 0.03}\n",
      " 20%|███████▍                             | 1000/5000 [16:31<1:01:53,  1.08it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.98s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.023562, 'eval_rouge-2': 6.455296000000001, 'eval_rouge-l': 25.246396, 'eval_bleu-4': 0.0331752972745821, 'eval_runtime': 13.6982, 'eval_samples_per_second': 3.65, 'eval_steps_per_second': 0.292, 'epoch': 0.03}\n",
      " 20%|███████▍                             | 1000/5000 [16:45<1:01:53,  1.08it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:09<00:00,  2.48s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1000\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.448, 'grad_norm': 6.997751712799072, 'learning_rate': 3.99e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4537, 'grad_norm': 7.448686599731445, 'learning_rate': 3.9800000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6514, 'grad_norm': 8.211316108703613, 'learning_rate': 3.97e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4059, 'grad_norm': 6.684374809265137, 'learning_rate': 3.960000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3902, 'grad_norm': 8.726245880126953, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3574, 'grad_norm': 7.8996901512146, 'learning_rate': 3.94e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3885, 'grad_norm': 7.051609039306641, 'learning_rate': 3.9300000000000007e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4598, 'grad_norm': 7.247015476226807, 'learning_rate': 3.9200000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5303, 'grad_norm': 7.134826183319092, 'learning_rate': 3.91e-05, 'epoch': 0.04}\n",
      "{'loss': 3.466, 'grad_norm': 6.617257118225098, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3424, 'grad_norm': 6.8565778732299805, 'learning_rate': 3.8900000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5199, 'grad_norm': 7.9134979248046875, 'learning_rate': 3.88e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4377, 'grad_norm': 7.3309173583984375, 'learning_rate': 3.8700000000000006e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3574, 'grad_norm': 8.029853820800781, 'learning_rate': 3.86e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3232, 'grad_norm': 7.729701995849609, 'learning_rate': 3.85e-05, 'epoch': 0.04}\n",
      "{'loss': 3.36, 'grad_norm': 7.321146011352539, 'learning_rate': 3.8400000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4529, 'grad_norm': 6.794680118560791, 'learning_rate': 3.83e-05, 'epoch': 0.04}\n",
      "{'loss': 3.474, 'grad_norm': 6.373709678649902, 'learning_rate': 3.82e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3582, 'grad_norm': 6.658304214477539, 'learning_rate': 3.8100000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4123, 'grad_norm': 6.382744789123535, 'learning_rate': 3.8e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2441, 'grad_norm': 6.528624057769775, 'learning_rate': 3.79e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3404, 'grad_norm': 7.454854488372803, 'learning_rate': 3.7800000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.376, 'grad_norm': 7.38369083404541, 'learning_rate': 3.77e-05, 'epoch': 0.04}\n",
      "{'loss': 3.377, 'grad_norm': 9.369096755981445, 'learning_rate': 3.76e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4477, 'grad_norm': 6.780214786529541, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.04}\n",
      "{'loss': 3.283, 'grad_norm': 7.49871301651001, 'learning_rate': 3.74e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4605, 'grad_norm': 7.119787693023682, 'learning_rate': 3.73e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3312, 'grad_norm': 7.1424241065979, 'learning_rate': 3.72e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3877, 'grad_norm': 6.839271545410156, 'learning_rate': 3.71e-05, 'epoch': 0.05}\n",
      "{'loss': 3.485, 'grad_norm': 7.491124153137207, 'learning_rate': 3.7e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4617, 'grad_norm': 7.067902088165283, 'learning_rate': 3.69e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4555, 'grad_norm': 6.657582759857178, 'learning_rate': 3.68e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4016, 'grad_norm': 10.287627220153809, 'learning_rate': 3.6700000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3057, 'grad_norm': 7.5425920486450195, 'learning_rate': 3.66e-05, 'epoch': 0.05}\n",
      "{'loss': 3.351, 'grad_norm': 7.466570854187012, 'learning_rate': 3.65e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3023, 'grad_norm': 7.957458972930908, 'learning_rate': 3.6400000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5156, 'grad_norm': 7.3537092208862305, 'learning_rate': 3.63e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3848, 'grad_norm': 7.193788051605225, 'learning_rate': 3.62e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3631, 'grad_norm': 7.099711894989014, 'learning_rate': 3.61e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4191, 'grad_norm': 6.623769283294678, 'learning_rate': 3.6e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3486, 'grad_norm': 7.45809268951416, 'learning_rate': 3.59e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2635, 'grad_norm': 7.535390853881836, 'learning_rate': 3.58e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3775, 'grad_norm': 7.771569728851318, 'learning_rate': 3.57e-05, 'epoch': 0.05}\n",
      "{'loss': 3.359, 'grad_norm': 7.170619964599609, 'learning_rate': 3.56e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2643, 'grad_norm': 6.764987468719482, 'learning_rate': 3.55e-05, 'epoch': 0.05}\n",
      "{'loss': 3.398, 'grad_norm': 7.413042068481445, 'learning_rate': 3.54e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4381, 'grad_norm': 10.17491340637207, 'learning_rate': 3.53e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2951, 'grad_norm': 6.712841510772705, 'learning_rate': 3.52e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4396, 'grad_norm': 7.463948726654053, 'learning_rate': 3.51e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4555, 'grad_norm': 6.829891681671143, 'learning_rate': 3.5e-05, 'epoch': 0.05}\n",
      " 30%|███████████▋                           | 1500/5000 [24:09<46:01,  1.27it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.13s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.72s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.366556, 'eval_rouge-2': 6.639612, 'eval_rouge-l': 25.190434, 'eval_bleu-4': 0.034062600934273685, 'eval_runtime': 36.5523, 'eval_samples_per_second': 1.368, 'eval_steps_per_second': 0.109, 'epoch': 0.05}\n",
      " 30%|███████████▋                           | 1500/5000 [24:45<46:01,  1.27it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:10<00:00,  2.58s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1500\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3398, 'grad_norm': 6.837435722351074, 'learning_rate': 3.49e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3873, 'grad_norm': 8.671278953552246, 'learning_rate': 3.48e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4385, 'grad_norm': 8.210297584533691, 'learning_rate': 3.4699999999999996e-05, 'epoch': 0.05}\n",
      "{'loss': 3.398, 'grad_norm': 6.863983154296875, 'learning_rate': 3.46e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4992, 'grad_norm': 7.2602972984313965, 'learning_rate': 3.45e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4061, 'grad_norm': 8.356240272521973, 'learning_rate': 3.4399999999999996e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4676, 'grad_norm': 7.844868183135986, 'learning_rate': 3.430000000000001e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4268, 'grad_norm': 7.667548179626465, 'learning_rate': 3.4200000000000005e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5094, 'grad_norm': 9.381078720092773, 'learning_rate': 3.41e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3924, 'grad_norm': 6.982611656188965, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3697, 'grad_norm': 7.904381275177002, 'learning_rate': 3.3900000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 3.368, 'grad_norm': 8.367115020751953, 'learning_rate': 3.38e-05, 'epoch': 0.06}\n",
      "{'loss': 3.473, 'grad_norm': 7.085567474365234, 'learning_rate': 3.3700000000000006e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3184, 'grad_norm': 8.01429271697998, 'learning_rate': 3.3600000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3721, 'grad_norm': 7.551950931549072, 'learning_rate': 3.35e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3055, 'grad_norm': 7.047082424163818, 'learning_rate': 3.3400000000000005e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4785, 'grad_norm': 8.319347381591797, 'learning_rate': 3.33e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3719, 'grad_norm': 7.0692925453186035, 'learning_rate': 3.32e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3762, 'grad_norm': 7.282199859619141, 'learning_rate': 3.3100000000000005e-05, 'epoch': 0.06}\n",
      "{'loss': 3.516, 'grad_norm': 6.837966442108154, 'learning_rate': 3.3e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4623, 'grad_norm': 7.306777000427246, 'learning_rate': 3.29e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5041, 'grad_norm': 7.349399089813232, 'learning_rate': 3.2800000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4012, 'grad_norm': 7.496603488922119, 'learning_rate': 3.27e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3986, 'grad_norm': 7.284237861633301, 'learning_rate': 3.26e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4725, 'grad_norm': 7.494788646697998, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4451, 'grad_norm': 7.734674453735352, 'learning_rate': 3.24e-05, 'epoch': 0.06}\n",
      "{'loss': 3.36, 'grad_norm': 8.558780670166016, 'learning_rate': 3.2300000000000006e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3525, 'grad_norm': 8.11609935760498, 'learning_rate': 3.2200000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3984, 'grad_norm': 8.067519187927246, 'learning_rate': 3.21e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3361, 'grad_norm': 7.649844646453857, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3809, 'grad_norm': 8.86260986328125, 'learning_rate': 3.19e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3389, 'grad_norm': 7.586513996124268, 'learning_rate': 3.18e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5795, 'grad_norm': 7.873928070068359, 'learning_rate': 3.1700000000000005e-05, 'epoch': 0.06}\n",
      "{'loss': 3.35, 'grad_norm': 8.576226234436035, 'learning_rate': 3.16e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4889, 'grad_norm': 8.806458473205566, 'learning_rate': 3.15e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3846, 'grad_norm': 7.396472454071045, 'learning_rate': 3.1400000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3219, 'grad_norm': 8.044366836547852, 'learning_rate': 3.13e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3037, 'grad_norm': 7.497974395751953, 'learning_rate': 3.12e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3984, 'grad_norm': 7.321104049682617, 'learning_rate': 3.1100000000000004e-05, 'epoch': 0.07}\n",
      "{'loss': 3.374, 'grad_norm': 7.7869744300842285, 'learning_rate': 3.1e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3916, 'grad_norm': 8.066460609436035, 'learning_rate': 3.09e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4779, 'grad_norm': 7.366364002227783, 'learning_rate': 3.08e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2787, 'grad_norm': 7.572554588317871, 'learning_rate': 3.07e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5033, 'grad_norm': 7.501689434051514, 'learning_rate': 3.06e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3646, 'grad_norm': 6.883505821228027, 'learning_rate': 3.05e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2848, 'grad_norm': 8.824028968811035, 'learning_rate': 3.04e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3723, 'grad_norm': 7.620704650878906, 'learning_rate': 3.03e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2375, 'grad_norm': 7.484353065490723, 'learning_rate': 3.02e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4148, 'grad_norm': 7.15908145904541, 'learning_rate': 3.01e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4684, 'grad_norm': 8.06341552734375, 'learning_rate': 3e-05, 'epoch': 0.07}\n",
      " 40%|███████████████▌                       | 2000/5000 [32:10<43:12,  1.16it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:25<00:25, 12.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:51<00:18, 18.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 30.623630000000002, 'eval_rouge-2': 6.5222180000000005, 'eval_rouge-l': 22.670682000000003, 'eval_bleu-4': 0.031648813859920216, 'eval_runtime': 95.8801, 'eval_samples_per_second': 0.521, 'eval_steps_per_second': 0.042, 'epoch': 0.07}\n",
      " 40%|███████████████▌                       | 2000/5000 [33:46<43:12,  1.16it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:09<00:00, 18.14s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2000\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3877, 'grad_norm': 8.66039752960205, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4955, 'grad_norm': 7.570542812347412, 'learning_rate': 2.98e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5592, 'grad_norm': 8.585640907287598, 'learning_rate': 2.97e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4939, 'grad_norm': 8.108970642089844, 'learning_rate': 2.96e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3678, 'grad_norm': 8.104866981506348, 'learning_rate': 2.95e-05, 'epoch': 0.07}\n",
      "{'loss': 3.326, 'grad_norm': 7.652172088623047, 'learning_rate': 2.94e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4412, 'grad_norm': 7.859943389892578, 'learning_rate': 2.93e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4174, 'grad_norm': 7.987238883972168, 'learning_rate': 2.9199999999999998e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4377, 'grad_norm': 7.415168762207031, 'learning_rate': 2.91e-05, 'epoch': 0.07}\n",
      "{'loss': 3.351, 'grad_norm': 7.836840629577637, 'learning_rate': 2.9e-05, 'epoch': 0.07}\n",
      "{'loss': 3.292, 'grad_norm': 7.630582809448242, 'learning_rate': 2.8899999999999998e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5811, 'grad_norm': 7.899662971496582, 'learning_rate': 2.88e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2549, 'grad_norm': 7.28056526184082, 'learning_rate': 2.87e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3574, 'grad_norm': 8.243165969848633, 'learning_rate': 2.86e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3992, 'grad_norm': 7.233987331390381, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.08}\n",
      "{'loss': 3.5234, 'grad_norm': 8.190317153930664, 'learning_rate': 2.84e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3934, 'grad_norm': 7.073838233947754, 'learning_rate': 2.83e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4123, 'grad_norm': 7.619967460632324, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3586, 'grad_norm': 7.620511054992676, 'learning_rate': 2.8100000000000005e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4305, 'grad_norm': 7.230944633483887, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4482, 'grad_norm': 6.699752330780029, 'learning_rate': 2.7900000000000004e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4158, 'grad_norm': 7.635942459106445, 'learning_rate': 2.7800000000000005e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4172, 'grad_norm': 8.080342292785645, 'learning_rate': 2.7700000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3701, 'grad_norm': 7.959227561950684, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2348, 'grad_norm': 8.437677383422852, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3627, 'grad_norm': 7.820092678070068, 'learning_rate': 2.7400000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4242, 'grad_norm': 8.457796096801758, 'learning_rate': 2.7300000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4678, 'grad_norm': 7.8062262535095215, 'learning_rate': 2.7200000000000004e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2947, 'grad_norm': 8.810651779174805, 'learning_rate': 2.7100000000000005e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3525, 'grad_norm': 8.05594539642334, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3182, 'grad_norm': 8.46494197845459, 'learning_rate': 2.6900000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3271, 'grad_norm': 8.963724136352539, 'learning_rate': 2.6800000000000004e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3666, 'grad_norm': 8.792357444763184, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3621, 'grad_norm': 7.527578353881836, 'learning_rate': 2.6600000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2615, 'grad_norm': 8.564956665039062, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3848, 'grad_norm': 8.257818222045898, 'learning_rate': 2.64e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3482, 'grad_norm': 7.829817771911621, 'learning_rate': 2.6300000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4914, 'grad_norm': 8.407703399658203, 'learning_rate': 2.6200000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2303, 'grad_norm': 8.599308013916016, 'learning_rate': 2.61e-05, 'epoch': 0.08}\n",
      "{'loss': 3.451, 'grad_norm': 7.255153656005859, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4566, 'grad_norm': 7.952578544616699, 'learning_rate': 2.5900000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2762, 'grad_norm': 7.882891654968262, 'learning_rate': 2.58e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3682, 'grad_norm': 7.566488265991211, 'learning_rate': 2.57e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3811, 'grad_norm': 8.02009105682373, 'learning_rate': 2.5600000000000002e-05, 'epoch': 0.09}\n",
      "{'loss': 3.2744, 'grad_norm': 7.579360008239746, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3088, 'grad_norm': 7.636131763458252, 'learning_rate': 2.54e-05, 'epoch': 0.09}\n",
      "{'loss': 3.2537, 'grad_norm': 8.628312110900879, 'learning_rate': 2.5300000000000002e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4367, 'grad_norm': 7.512238025665283, 'learning_rate': 2.5200000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4738, 'grad_norm': 7.8891472816467285, 'learning_rate': 2.51e-05, 'epoch': 0.09}\n",
      "{'loss': 3.393, 'grad_norm': 9.457147598266602, 'learning_rate': 2.5e-05, 'epoch': 0.09}\n",
      " 50%|███████████████████▌                   | 2500/5000 [41:10<36:26,  1.14it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:05<00:05,  2.65s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:08<00:02,  2.88s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.894414, 'eval_rouge-2': 7.23011, 'eval_rouge-l': 25.167156, 'eval_bleu-4': 0.03533911016191969, 'eval_runtime': 37.9283, 'eval_samples_per_second': 1.318, 'eval_steps_per_second': 0.105, 'epoch': 0.09}\n",
      " 50%|███████████████████▌                   | 2500/5000 [41:48<36:26,  1.14it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:11<00:00,  2.93s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2500\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.2973, 'grad_norm': 8.263565063476562, 'learning_rate': 2.4900000000000002e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3396, 'grad_norm': 9.418621063232422, 'learning_rate': 2.48e-05, 'epoch': 0.09}\n",
      "{'loss': 3.2459, 'grad_norm': 7.703180313110352, 'learning_rate': 2.47e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3887, 'grad_norm': 8.171995162963867, 'learning_rate': 2.46e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3828, 'grad_norm': 7.231782913208008, 'learning_rate': 2.45e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3965, 'grad_norm': 8.20529842376709, 'learning_rate': 2.44e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4695, 'grad_norm': 7.901302337646484, 'learning_rate': 2.43e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4828, 'grad_norm': 8.555204391479492, 'learning_rate': 2.4200000000000002e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3684, 'grad_norm': 8.278306007385254, 'learning_rate': 2.41e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4777, 'grad_norm': 8.501630783081055, 'learning_rate': 2.4e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3477, 'grad_norm': 8.012674331665039, 'learning_rate': 2.39e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4102, 'grad_norm': 7.662302017211914, 'learning_rate': 2.38e-05, 'epoch': 0.09}\n",
      "{'loss': 3.5248, 'grad_norm': 7.715944766998291, 'learning_rate': 2.37e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4422, 'grad_norm': 8.347634315490723, 'learning_rate': 2.36e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4029, 'grad_norm': 7.8511528968811035, 'learning_rate': 2.35e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3455, 'grad_norm': 7.965017318725586, 'learning_rate': 2.3400000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4062, 'grad_norm': 8.939918518066406, 'learning_rate': 2.3300000000000004e-05, 'epoch': 0.09}\n",
      "{'loss': 3.2645, 'grad_norm': 7.534878253936768, 'learning_rate': 2.32e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4721, 'grad_norm': 8.297586441040039, 'learning_rate': 2.3100000000000002e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4379, 'grad_norm': 8.879554748535156, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4193, 'grad_norm': 8.152324676513672, 'learning_rate': 2.29e-05, 'epoch': 0.09}\n",
      "{'loss': 3.2443, 'grad_norm': 7.440194129943848, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3814, 'grad_norm': 8.161179542541504, 'learning_rate': 2.2700000000000003e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3879, 'grad_norm': 8.235527992248535, 'learning_rate': 2.26e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4521, 'grad_norm': 8.84763240814209, 'learning_rate': 2.25e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4, 'grad_norm': 8.038077354431152, 'learning_rate': 2.2400000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3412, 'grad_norm': 8.210636138916016, 'learning_rate': 2.23e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2527, 'grad_norm': 8.349793434143066, 'learning_rate': 2.22e-05, 'epoch': 0.1}\n",
      "{'loss': 3.275, 'grad_norm': 7.914191722869873, 'learning_rate': 2.2100000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2311, 'grad_norm': 7.719367504119873, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4357, 'grad_norm': 8.17683219909668, 'learning_rate': 2.19e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3584, 'grad_norm': 7.654301643371582, 'learning_rate': 2.18e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3893, 'grad_norm': 8.043334007263184, 'learning_rate': 2.1700000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4396, 'grad_norm': 8.753227233886719, 'learning_rate': 2.16e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4045, 'grad_norm': 8.640907287597656, 'learning_rate': 2.15e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3246, 'grad_norm': 8.399273872375488, 'learning_rate': 2.1400000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3625, 'grad_norm': 8.343362808227539, 'learning_rate': 2.13e-05, 'epoch': 0.1}\n",
      "{'loss': 3.5, 'grad_norm': 9.380899429321289, 'learning_rate': 2.12e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2957, 'grad_norm': 8.002314567565918, 'learning_rate': 2.11e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3252, 'grad_norm': 8.828001022338867, 'learning_rate': 2.1e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2961, 'grad_norm': 7.880640029907227, 'learning_rate': 2.09e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2389, 'grad_norm': 7.4922966957092285, 'learning_rate': 2.08e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3521, 'grad_norm': 9.072588920593262, 'learning_rate': 2.07e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2455, 'grad_norm': 7.900532245635986, 'learning_rate': 2.06e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3547, 'grad_norm': 8.219547271728516, 'learning_rate': 2.05e-05, 'epoch': 0.1}\n",
      "{'loss': 3.2088, 'grad_norm': 9.061513900756836, 'learning_rate': 2.04e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4443, 'grad_norm': 8.718775749206543, 'learning_rate': 2.0300000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4217, 'grad_norm': 8.77509593963623, 'learning_rate': 2.0200000000000003e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4533, 'grad_norm': 7.994718551635742, 'learning_rate': 2.01e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3592, 'grad_norm': 7.621406555175781, 'learning_rate': 2e-05, 'epoch': 0.1}\n",
      " 60%|███████████████████████▍               | 3000/5000 [49:14<27:44,  1.20it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.48s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:30<00:11, 11.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.582192000000006, 'eval_rouge-2': 7.0263800000000005, 'eval_rouge-l': 23.956662, 'eval_bleu-4': 0.03228338350845153, 'eval_runtime': 74.9239, 'eval_samples_per_second': 0.667, 'eval_steps_per_second': 0.053, 'epoch': 0.1}\n",
      " 60%|███████████████████████▍               | 3000/5000 [50:29<27:44,  1.20it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:48<00:00, 14.33s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.4691, 'grad_norm': 8.179304122924805, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3516, 'grad_norm': 7.874887943267822, 'learning_rate': 1.9800000000000004e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3545, 'grad_norm': 8.240294456481934, 'learning_rate': 1.97e-05, 'epoch': 0.11}\n",
      "{'loss': 3.2273, 'grad_norm': 7.576611518859863, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3893, 'grad_norm': 8.548114776611328, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.11}\n",
      "{'loss': 3.5312, 'grad_norm': 7.654369354248047, 'learning_rate': 1.94e-05, 'epoch': 0.11}\n",
      "{'loss': 3.2953, 'grad_norm': 7.940248012542725, 'learning_rate': 1.93e-05, 'epoch': 0.11}\n",
      "{'loss': 3.2943, 'grad_norm': 9.889776229858398, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.11}\n",
      "{'loss': 3.201, 'grad_norm': 8.715892791748047, 'learning_rate': 1.91e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3854, 'grad_norm': 7.659997463226318, 'learning_rate': 1.9e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3416, 'grad_norm': 8.809901237487793, 'learning_rate': 1.8900000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3217, 'grad_norm': 8.384994506835938, 'learning_rate': 1.88e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3805, 'grad_norm': 9.1993989944458, 'learning_rate': 1.87e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3016, 'grad_norm': 8.416421890258789, 'learning_rate': 1.86e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4492, 'grad_norm': 8.397589683532715, 'learning_rate': 1.85e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4287, 'grad_norm': 8.671771049499512, 'learning_rate': 1.84e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4842, 'grad_norm': 7.757935523986816, 'learning_rate': 1.83e-05, 'epoch': 0.11}\n",
      "{'loss': 3.2168, 'grad_norm': 8.239444732666016, 'learning_rate': 1.8200000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3607, 'grad_norm': 7.401950836181641, 'learning_rate': 1.81e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4117, 'grad_norm': 8.385684967041016, 'learning_rate': 1.8e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3818, 'grad_norm': 9.223533630371094, 'learning_rate': 1.79e-05, 'epoch': 0.11}\n",
      "{'loss': 3.3943, 'grad_norm': 7.623672008514404, 'learning_rate': 1.78e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4766, 'grad_norm': 8.6920747756958, 'learning_rate': 1.77e-05, 'epoch': 0.11}\n",
      "{'loss': 3.2166, 'grad_norm': 8.835351943969727, 'learning_rate': 1.76e-05, 'epoch': 0.11}\n",
      "{'loss': 3.41, 'grad_norm': 8.43702220916748, 'learning_rate': 1.75e-05, 'epoch': 0.11}\n",
      "{'loss': 3.366, 'grad_norm': 10.236673355102539, 'learning_rate': 1.74e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4123, 'grad_norm': 8.361246109008789, 'learning_rate': 1.73e-05, 'epoch': 0.11}\n",
      "{'loss': 3.293, 'grad_norm': 7.950584888458252, 'learning_rate': 1.7199999999999998e-05, 'epoch': 0.11}\n",
      "{'loss': 3.2998, 'grad_norm': 9.814288139343262, 'learning_rate': 1.7100000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4025, 'grad_norm': 7.359404563903809, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3549, 'grad_norm': 7.861804962158203, 'learning_rate': 1.69e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2273, 'grad_norm': 8.168889999389648, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3937, 'grad_norm': 9.072976112365723, 'learning_rate': 1.6700000000000003e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3777, 'grad_norm': 8.10163402557373, 'learning_rate': 1.66e-05, 'epoch': 0.12}\n",
      "{'loss': 3.283, 'grad_norm': 9.149909019470215, 'learning_rate': 1.65e-05, 'epoch': 0.12}\n",
      "{'loss': 3.4244, 'grad_norm': 8.041630744934082, 'learning_rate': 1.6400000000000002e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3283, 'grad_norm': 7.538507461547852, 'learning_rate': 1.63e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3723, 'grad_norm': 7.798099040985107, 'learning_rate': 1.62e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2799, 'grad_norm': 9.34572982788086, 'learning_rate': 1.6100000000000002e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3563, 'grad_norm': 7.796827793121338, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.12}\n",
      "{'loss': 3.201, 'grad_norm': 8.760631561279297, 'learning_rate': 1.59e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2895, 'grad_norm': 9.022807121276855, 'learning_rate': 1.58e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3414, 'grad_norm': 8.948742866516113, 'learning_rate': 1.5700000000000002e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3039, 'grad_norm': 8.384121894836426, 'learning_rate': 1.56e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3297, 'grad_norm': 8.825644493103027, 'learning_rate': 1.55e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3398, 'grad_norm': 9.063819885253906, 'learning_rate': 1.54e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2709, 'grad_norm': 9.12978458404541, 'learning_rate': 1.53e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2754, 'grad_norm': 9.952362060546875, 'learning_rate': 1.52e-05, 'epoch': 0.12}\n",
      "{'loss': 3.408, 'grad_norm': 8.279414176940918, 'learning_rate': 1.51e-05, 'epoch': 0.12}\n",
      "{'loss': 3.4424, 'grad_norm': 8.232932090759277, 'learning_rate': 1.5e-05, 'epoch': 0.12}\n",
      " 70%|███████████████████████████▎           | 3500/5000 [57:49<21:42,  1.15it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.32s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.62s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.566598, 'eval_rouge-2': 6.880014000000001, 'eval_rouge-l': 25.092078, 'eval_bleu-4': 0.032619579079439215, 'eval_runtime': 35.9503, 'eval_samples_per_second': 1.391, 'eval_steps_per_second': 0.111, 'epoch': 0.12}\n",
      " 70%|███████████████████████████▎           | 3500/5000 [58:24<21:42,  1.15it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:09<00:00,  2.34s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3500\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3883, 'grad_norm': 8.947819709777832, 'learning_rate': 1.49e-05, 'epoch': 0.12}\n",
      "{'loss': 3.316, 'grad_norm': 8.94828987121582, 'learning_rate': 1.48e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2787, 'grad_norm': 8.132102012634277, 'learning_rate': 1.47e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3006, 'grad_norm': 8.960626602172852, 'learning_rate': 1.4599999999999999e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3586, 'grad_norm': 8.705967903137207, 'learning_rate': 1.45e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2137, 'grad_norm': 8.466059684753418, 'learning_rate': 1.44e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3135, 'grad_norm': 7.823843002319336, 'learning_rate': 1.43e-05, 'epoch': 0.12}\n",
      "{'loss': 3.4275, 'grad_norm': 9.384418487548828, 'learning_rate': 1.42e-05, 'epoch': 0.12}\n",
      "{'loss': 3.2422, 'grad_norm': 9.371258735656738, 'learning_rate': 1.4099999999999999e-05, 'epoch': 0.13}\n",
      "{'loss': 3.1852, 'grad_norm': 8.542067527770996, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2639, 'grad_norm': 10.688029289245605, 'learning_rate': 1.3900000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 3.5229, 'grad_norm': 8.201922416687012, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3937, 'grad_norm': 9.109646797180176, 'learning_rate': 1.3700000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2006, 'grad_norm': 9.009145736694336, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3018, 'grad_norm': 10.00816822052002, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2008, 'grad_norm': 8.980449676513672, 'learning_rate': 1.3400000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3029, 'grad_norm': 8.539236068725586, 'learning_rate': 1.3300000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3746, 'grad_norm': 8.780318260192871, 'learning_rate': 1.32e-05, 'epoch': 0.13}\n",
      "{'loss': 3.4006, 'grad_norm': 8.176715850830078, 'learning_rate': 1.3100000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3969, 'grad_norm': 9.39802360534668, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3676, 'grad_norm': 9.544647216796875, 'learning_rate': 1.29e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3861, 'grad_norm': 9.74763298034668, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.165, 'grad_norm': 10.704689979553223, 'learning_rate': 1.27e-05, 'epoch': 0.13}\n",
      "{'loss': 3.4059, 'grad_norm': 9.084773063659668, 'learning_rate': 1.2600000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2301, 'grad_norm': 8.260934829711914, 'learning_rate': 1.25e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2062, 'grad_norm': 8.426517486572266, 'learning_rate': 1.24e-05, 'epoch': 0.13}\n",
      "{'loss': 3.249, 'grad_norm': 9.996965408325195, 'learning_rate': 1.23e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2752, 'grad_norm': 8.348227500915527, 'learning_rate': 1.22e-05, 'epoch': 0.13}\n",
      "{'loss': 3.4656, 'grad_norm': 8.030095100402832, 'learning_rate': 1.2100000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2611, 'grad_norm': 8.058856010437012, 'learning_rate': 1.2e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3436, 'grad_norm': 10.138822555541992, 'learning_rate': 1.19e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2287, 'grad_norm': 9.062579154968262, 'learning_rate': 1.18e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3926, 'grad_norm': 8.761282920837402, 'learning_rate': 1.1700000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3129, 'grad_norm': 8.933921813964844, 'learning_rate': 1.16e-05, 'epoch': 0.13}\n",
      "{'loss': 3.2871, 'grad_norm': 8.774215698242188, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3236, 'grad_norm': 9.129841804504395, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 3.457, 'grad_norm': 8.008439064025879, 'learning_rate': 1.13e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4797, 'grad_norm': 8.201080322265625, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4137, 'grad_norm': 8.1409912109375, 'learning_rate': 1.11e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4535, 'grad_norm': 8.845293998718262, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 3.2814, 'grad_norm': 8.754626274108887, 'learning_rate': 1.09e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3375, 'grad_norm': 9.652393341064453, 'learning_rate': 1.08e-05, 'epoch': 0.14}\n",
      "{'loss': 3.383, 'grad_norm': 7.8347578048706055, 'learning_rate': 1.0700000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 3.5014, 'grad_norm': 8.774374008178711, 'learning_rate': 1.06e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3336, 'grad_norm': 8.986586570739746, 'learning_rate': 1.05e-05, 'epoch': 0.14}\n",
      "{'loss': 3.2869, 'grad_norm': 8.63016414642334, 'learning_rate': 1.04e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4139, 'grad_norm': 8.019036293029785, 'learning_rate': 1.03e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4043, 'grad_norm': 8.804017066955566, 'learning_rate': 1.02e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4363, 'grad_norm': 8.572220802307129, 'learning_rate': 1.0100000000000002e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3813, 'grad_norm': 9.478486061096191, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      " 80%|█████████████████████████████▌       | 4000/5000 [1:05:53<13:56,  1.20it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:25<00:25, 12.94s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:29<00:09,  9.06s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 33.118442, 'eval_rouge-2': 7.3648880000000005, 'eval_rouge-l': 24.985168, 'eval_bleu-4': 0.03426780216720712, 'eval_runtime': 58.216, 'eval_samples_per_second': 0.859, 'eval_steps_per_second': 0.069, 'epoch': 0.14}\n",
      " 80%|█████████████████████████████▌       | 4000/5000 [1:06:51<13:56,  1.20it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:32<00:00,  6.51s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-4000\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.2684, 'grad_norm': 10.753947257995605, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3465, 'grad_norm': 8.363122940063477, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 3.4553, 'grad_norm': 8.730976104736328, 'learning_rate': 9.7e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3713, 'grad_norm': 9.275322914123535, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 3.2621, 'grad_norm': 8.515057563781738, 'learning_rate': 9.5e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3025, 'grad_norm': 9.134584426879883, 'learning_rate': 9.4e-06, 'epoch': 0.14}\n",
      "{'loss': 3.177, 'grad_norm': 8.067008972167969, 'learning_rate': 9.3e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3936, 'grad_norm': 8.974719047546387, 'learning_rate': 9.2e-06, 'epoch': 0.14}\n",
      "{'loss': 3.4258, 'grad_norm': 9.562321662902832, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3314, 'grad_norm': 9.110989570617676, 'learning_rate': 9e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3559, 'grad_norm': 10.857179641723633, 'learning_rate': 8.9e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3203, 'grad_norm': 8.485292434692383, 'learning_rate': 8.8e-06, 'epoch': 0.14}\n",
      "{'loss': 3.418, 'grad_norm': 7.883821487426758, 'learning_rate': 8.7e-06, 'epoch': 0.14}\n",
      "{'loss': 3.283, 'grad_norm': 8.273262977600098, 'learning_rate': 8.599999999999999e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3346, 'grad_norm': 9.031291007995605, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.14}\n",
      "{'loss': 3.3336, 'grad_norm': 8.770218849182129, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2453, 'grad_norm': 9.618197441101074, 'learning_rate': 8.3e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3342, 'grad_norm': 8.522326469421387, 'learning_rate': 8.200000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.4773, 'grad_norm': 10.063302993774414, 'learning_rate': 8.1e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3762, 'grad_norm': 8.41025161743164, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3348, 'grad_norm': 7.9632158279418945, 'learning_rate': 7.9e-06, 'epoch': 0.15}\n",
      "{'loss': 3.317, 'grad_norm': 8.753010749816895, 'learning_rate': 7.8e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2906, 'grad_norm': 9.028636932373047, 'learning_rate': 7.7e-06, 'epoch': 0.15}\n",
      "{'loss': 3.4785, 'grad_norm': 8.058526992797852, 'learning_rate': 7.6e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3992, 'grad_norm': 8.390913963317871, 'learning_rate': 7.5e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3533, 'grad_norm': 8.77169418334961, 'learning_rate': 7.4e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2428, 'grad_norm': 9.773477554321289, 'learning_rate': 7.2999999999999996e-06, 'epoch': 0.15}\n",
      "{'loss': 3.1848, 'grad_norm': 8.255354881286621, 'learning_rate': 7.2e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2977, 'grad_norm': 8.679518699645996, 'learning_rate': 7.1e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3895, 'grad_norm': 9.003621101379395, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3963, 'grad_norm': 8.567415237426758, 'learning_rate': 6.900000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.185, 'grad_norm': 8.407103538513184, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2205, 'grad_norm': 8.932089805603027, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3635, 'grad_norm': 9.323861122131348, 'learning_rate': 6.6e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2898, 'grad_norm': 8.565463066101074, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2881, 'grad_norm': 9.370940208435059, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3523, 'grad_norm': 9.2452392578125, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3891, 'grad_norm': 8.911859512329102, 'learning_rate': 6.2e-06, 'epoch': 0.15}\n",
      "{'loss': 3.1936, 'grad_norm': 7.9998273849487305, 'learning_rate': 6.1e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3184, 'grad_norm': 8.551567077636719, 'learning_rate': 6e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2744, 'grad_norm': 10.047826766967773, 'learning_rate': 5.9e-06, 'epoch': 0.15}\n",
      "{'loss': 3.3396, 'grad_norm': 8.415565490722656, 'learning_rate': 5.8e-06, 'epoch': 0.15}\n",
      "{'loss': 3.4209, 'grad_norm': 9.227760314941406, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.15}\n",
      "{'loss': 3.1221, 'grad_norm': 9.179256439208984, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 3.2576, 'grad_norm': 9.100034713745117, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3516, 'grad_norm': 9.4490966796875, 'learning_rate': 5.4e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4342, 'grad_norm': 10.03878402709961, 'learning_rate': 5.3e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3705, 'grad_norm': 8.18057632446289, 'learning_rate': 5.2e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3189, 'grad_norm': 9.67108154296875, 'learning_rate': 5.1e-06, 'epoch': 0.16}\n",
      "{'loss': 3.368, 'grad_norm': 8.838530540466309, 'learning_rate': 5e-06, 'epoch': 0.16}\n",
      " 90%|█████████████████████████████████▎   | 4500/5000 [1:14:17<07:57,  1.05it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:25<00:25, 12.93s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:51<00:18, 18.03s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.350586, 'eval_rouge-2': 6.842454, 'eval_rouge-l': 24.117569999999997, 'eval_bleu-4': 0.03166042054556717, 'eval_runtime': 79.5884, 'eval_samples_per_second': 0.628, 'eval_steps_per_second': 0.05, 'epoch': 0.16}\n",
      " 90%|█████████████████████████████████▎   | 4500/5000 [1:15:37<07:57,  1.05it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:53<00:00, 12.10s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-4500\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'loss': 3.4502, 'grad_norm': 9.156636238098145, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.16}\n",
      "{'loss': 3.1963, 'grad_norm': 10.31143856048584, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3705, 'grad_norm': 9.992913246154785, 'learning_rate': 4.7e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3469, 'grad_norm': 9.116534233093262, 'learning_rate': 4.6e-06, 'epoch': 0.16}\n",
      "{'loss': 3.1916, 'grad_norm': 8.960427284240723, 'learning_rate': 4.5e-06, 'epoch': 0.16}\n",
      "{'loss': 3.34, 'grad_norm': 10.132002830505371, 'learning_rate': 4.4e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4059, 'grad_norm': 8.873003005981445, 'learning_rate': 4.2999999999999995e-06, 'epoch': 0.16}\n",
      "{'loss': 3.25, 'grad_norm': 8.933907508850098, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3342, 'grad_norm': 9.954017639160156, 'learning_rate': 4.1000000000000006e-06, 'epoch': 0.16}\n",
      "{'loss': 3.2838, 'grad_norm': 10.458900451660156, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 3.2475, 'grad_norm': 10.44653034210205, 'learning_rate': 3.9e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4057, 'grad_norm': 8.90979290008545, 'learning_rate': 3.8e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3193, 'grad_norm': 10.136809349060059, 'learning_rate': 3.7e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3623, 'grad_norm': 9.603639602661133, 'learning_rate': 3.6e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3139, 'grad_norm': 8.728217124938965, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3949, 'grad_norm': 8.572542190551758, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3824, 'grad_norm': 10.369405746459961, 'learning_rate': 3.3e-06, 'epoch': 0.16}\n",
      "{'loss': 3.5307, 'grad_norm': 9.774340629577637, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.16}\n",
      "{'loss': 3.3586, 'grad_norm': 9.430370330810547, 'learning_rate': 3.1e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4953, 'grad_norm': 9.319965362548828, 'learning_rate': 3e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4234, 'grad_norm': 9.859830856323242, 'learning_rate': 2.9e-06, 'epoch': 0.16}\n",
      "{'loss': 3.2953, 'grad_norm': 9.070358276367188, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4193, 'grad_norm': 7.8667826652526855, 'learning_rate': 2.7e-06, 'epoch': 0.17}\n",
      "{'loss': 3.2523, 'grad_norm': 8.68185806274414, 'learning_rate': 2.6e-06, 'epoch': 0.17}\n",
      "{'loss': 3.4131, 'grad_norm': 9.36903190612793, 'learning_rate': 2.5e-06, 'epoch': 0.17}\n",
      "{'loss': 3.326, 'grad_norm': 8.488428115844727, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.17}\n",
      "{'loss': 3.334, 'grad_norm': 9.19690990447998, 'learning_rate': 2.3e-06, 'epoch': 0.17}\n",
      "{'loss': 3.3375, 'grad_norm': 8.894542694091797, 'learning_rate': 2.2e-06, 'epoch': 0.17}\n",
      "{'loss': 3.4152, 'grad_norm': 9.616287231445312, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 3.4066, 'grad_norm': 9.788228988647461, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.17}\n",
      "{'loss': 3.5645, 'grad_norm': 9.390854835510254, 'learning_rate': 1.9e-06, 'epoch': 0.17}\n",
      "{'loss': 3.2639, 'grad_norm': 10.40858268737793, 'learning_rate': 1.8e-06, 'epoch': 0.17}\n",
      "{'loss': 3.1926, 'grad_norm': 8.248465538024902, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 3.2434, 'grad_norm': 8.757920265197754, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 3.3326, 'grad_norm': 10.493969917297363, 'learning_rate': 1.5e-06, 'epoch': 0.17}\n",
      "{'loss': 3.1986, 'grad_norm': 8.779265403747559, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 3.266, 'grad_norm': 8.241680145263672, 'learning_rate': 1.3e-06, 'epoch': 0.17}\n",
      "{'loss': 3.3895, 'grad_norm': 9.043349266052246, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 3.4139, 'grad_norm': 8.158859252929688, 'learning_rate': 1.1e-06, 'epoch': 0.17}\n",
      "{'loss': 3.3025, 'grad_norm': 9.835896492004395, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 3.2437, 'grad_norm': 8.893661499023438, 'learning_rate': 9e-07, 'epoch': 0.17}\n",
      "{'loss': 3.3844, 'grad_norm': 8.83681583404541, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.17}\n",
      "{'loss': 3.1992, 'grad_norm': 9.75949764251709, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.17}\n",
      "{'loss': 3.3162, 'grad_norm': 9.000393867492676, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.17}\n",
      "{'loss': 3.3172, 'grad_norm': 9.92842960357666, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.17}\n",
      "{'loss': 3.4357, 'grad_norm': 9.111879348754883, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.17}\n",
      "{'loss': 3.3102, 'grad_norm': 9.005753517150879, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.17}\n",
      "{'loss': 3.2979, 'grad_norm': 9.745713233947754, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.17}\n",
      "{'loss': 3.234, 'grad_norm': 9.790050506591797, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.17}\n",
      "{'loss': 3.1773, 'grad_norm': 8.28215217590332, 'learning_rate': 0.0, 'epoch': 0.17}\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:23:00<00:00,  1.19it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 50%|██████████████████████▌                      | 2/4 [00:25<00:25, 12.92s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:50<00:18, 18.01s/it]\u001b[ASetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.13327399999999, 'eval_rouge-2': 6.839542, 'eval_rouge-l': 22.955968, 'eval_bleu-4': 0.030800940235529706, 'eval_runtime': 79.9886, 'eval_samples_per_second': 0.625, 'eval_steps_per_second': 0.05, 'epoch': 0.17}\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:24:20<00:00,  1.19it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:53<00:00, 12.26s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-5000\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/workspace/models/chatglm3-6b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 5061.8714, 'train_samples_per_second': 3.951, 'train_steps_per_second': 0.988, 'train_loss': 3.40149140625, 'epoch': 0.17}\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:24:21<00:00,  1.01s/it]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|                                                    | 0/67 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|█▎                                          | 2/67 [00:25<14:01, 12.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|█▉                                          | 3/67 [00:51<19:14, 18.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|██▋                                         | 4/67 [01:16<21:46, 20.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|███▎                                        | 5/67 [01:41<22:58, 22.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|███▉                                        | 6/67 [02:06<23:43, 23.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|████▌                                       | 7/67 [02:11<17:10, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█████▎                                      | 8/67 [02:16<13:11, 13.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█████▉                                      | 9/67 [02:20<10:16, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|██████▍                                    | 10/67 [02:26<08:40,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|███████                                    | 11/67 [02:30<06:56,  7.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|███████▋                                   | 12/67 [02:55<11:44, 12.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|████████▎                                  | 13/67 [02:58<08:57,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|████████▉                                  | 14/67 [03:02<07:12,  8.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|█████████▋                                 | 15/67 [03:06<05:56,  6.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██████████▎                                | 16/67 [03:10<05:00,  5.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██████████▉                                | 17/67 [03:14<04:26,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|███████████▌                               | 18/67 [03:40<09:30, 11.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|████████████▏                              | 19/67 [04:05<12:34, 15.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|████████████▊                              | 20/67 [04:31<14:34, 18.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|█████████████▍                             | 21/67 [04:38<11:37, 15.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|██████████████                             | 22/67 [04:42<08:59, 11.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|██████████████▊                            | 23/67 [05:08<11:44, 16.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███████████████▍                           | 24/67 [05:12<08:58, 12.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|████████████████                           | 25/67 [05:16<06:59,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|████████████████▋                          | 26/67 [05:41<09:54, 14.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|█████████████████▎                         | 27/67 [05:45<07:28, 11.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|█████████████████▉                         | 28/67 [06:10<10:02, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|██████████████████▌                        | 29/67 [06:35<11:37, 18.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|███████████████████▎                       | 30/67 [07:01<12:40, 20.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|███████████████████▉                       | 31/67 [07:26<13:11, 21.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████████████████████▌                      | 32/67 [07:51<13:21, 22.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|█████████████████████▏                     | 33/67 [07:55<09:42, 17.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████████████████████▊                     | 34/67 [08:20<10:44, 19.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|██████████████████████▍                    | 35/67 [08:45<11:19, 21.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|███████████████████████                    | 36/67 [09:11<11:38, 22.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|███████████████████████▋                   | 37/67 [09:15<08:29, 16.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|████████████████████████▍                  | 38/67 [09:40<09:23, 19.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████████████████████████                  | 39/67 [10:05<09:53, 21.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████████████████████████▋                 | 40/67 [10:08<07:07, 15.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████████████████████████▎                | 41/67 [10:34<08:06, 18.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████████████████████████▉                | 42/67 [10:38<05:54, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|███████████████████████████▌               | 43/67 [11:03<07:00, 17.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|████████████████████████████▏              | 44/67 [11:28<07:35, 19.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|████████████████████████████▉              | 45/67 [11:53<07:53, 21.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|█████████████████████████████▌             | 46/67 [11:57<05:37, 16.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████████████████████████████▏            | 47/67 [12:01<04:07, 12.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|██████████████████████████████▊            | 48/67 [12:26<05:09, 16.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████████████████████████████▍           | 49/67 [12:51<05:40, 18.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|████████████████████████████████           | 50/67 [12:54<04:00, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|████████████████████████████████▋          | 51/67 [12:58<02:55, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|█████████████████████████████████▎         | 52/67 [13:23<03:48, 15.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|██████████████████████████████████         | 53/67 [13:48<04:16, 18.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|██████████████████████████████████▋        | 54/67 [14:14<04:25, 20.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|███████████████████████████████████▎       | 55/67 [14:39<04:22, 21.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|███████████████████████████████████▉       | 56/67 [15:04<04:12, 22.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████████████████████████████████▌      | 57/67 [15:30<03:58, 23.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|█████████████████████████████████████▏     | 58/67 [15:56<03:39, 24.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|█████████████████████████████████████▊     | 59/67 [16:00<02:26, 18.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|██████████████████████████████████████▌    | 60/67 [16:03<01:35, 13.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|███████████████████████████████████████▏   | 61/67 [16:06<01:02, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|███████████████████████████████████████▊   | 62/67 [16:32<01:15, 15.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|████████████████████████████████████████▍  | 63/67 [16:35<00:46, 11.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████████████████████████████████████  | 64/67 [16:39<00:27,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████████████████████████████████████▋ | 65/67 [16:42<00:14,  7.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|██████████████████████████████████████████▎| 66/67 [16:46<00:06,  6.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|███████████████████████████████████████████| 67/67 [16:56<00:00, 15.18s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python finetune_hf.py  data/AdvertiseGen_fix  /mnt/workspace/models/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {
    "id": "d9418f6c5c264601"
   },
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T06:23:52.725227Z",
     "start_time": "2024-04-14T06:23:41.284552Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-10T23:05:14.065506Z",
     "iopub.status.busy": "2025-03-10T23:05:14.065173Z",
     "iopub.status.idle": "2025-03-10T23:05:54.637726Z",
     "shell.execute_reply": "2025-03-10T23:05:54.637168Z",
     "shell.execute_reply.started": "2025-03-10T23:05:14.065486Z"
    },
    "id": "5060015c24e97ae",
    "outputId": "d3f03d0d-46bf-4c74-9b00-dc0160da0e15",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-11 07:05:17.999237: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-11 07:05:18.039644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 07:05:18.832317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:27<00:00,  3.90s/it]\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "这款连衣裙的版型设计是那种显瘦的，不规则的裙摆设计，百褶的裙摆，搭配上木耳边和网纱拼接的元素，彰显出性感优雅的气息。裙身压褶的元素，让这款连衣裙看起来更加优雅。不规则的袖口设计，搭配上拉链套头的设计，让这款连衣裙更加精致。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-5000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "id": "18cd83087f096094"
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
